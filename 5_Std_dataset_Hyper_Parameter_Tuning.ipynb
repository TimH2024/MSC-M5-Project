{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimH2024/MSC-M5-Project/blob/main/5_Std_dataset_Hyper_Parameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93259bc1",
      "metadata": {
        "id": "93259bc1"
      },
      "source": [
        "# 5. Hyper Parameter Tuning Results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INSTALL LIBRARIES"
      ],
      "metadata": {
        "id": "ah73YrZPRcSx"
      },
      "id": "ah73YrZPRcSx"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow keras keras-tuner numpy pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuALBXMf--2f",
        "outputId": "6bf3b49f-7819-45ba-eb3d-985452cc7016"
      },
      "id": "nuALBXMf--2f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Machine learning and preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# TensorFlow/Keras for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Keras Tuner for hyperparameter tuning\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "otEckcql_AcO"
      },
      "id": "otEckcql_AcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD FILES"
      ],
      "metadata": {
        "id": "0FwxgZkoRjiU"
      },
      "id": "0FwxgZkoRjiU"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Define the full file path\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_resultsStd.csv')\n",
        "\n",
        "# Check if the file exists and load it\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_resultsStd = pd.read_csv(master_results_file_path)\n",
        "    print(f\"File 'master_resultsStd.csv' loaded successfully!\")\n",
        "    print(master_resultsStd.head())  # Display the first few rows of the DataFrame\n",
        "else:\n",
        "    print(f\"File 'master_resultsStd.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD8vUMglARbt",
        "outputId": "4c53b2f2-e253-42c9-83e7-1540e5e4b698"
      },
      "id": "YD8vUMglARbt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File 'master_resultsStd.csv' loaded successfully!\n",
            "      Target                        Model            Train R²   Test R²  \\\n",
            "0  new_price            Linear Regression  0.6297378908089446  0.627819   \n",
            "1  new_price      Random Forest Regressor   0.973289789332776  0.824091   \n",
            "2  new_price            XGBoost Regressor  0.8270074320236708  0.766067   \n",
            "3  new_price  Gradient Boosting Regressor  0.7699284396872543  0.746053   \n",
            "4         PC            Linear Regression   0.973660068974925  0.974082   \n",
            "\n",
            "        MAE       MSE      RMSE        MAPE Comments                      Type  \n",
            "0  0.489318  0.373920  0.611490  249.308212   Normal  Simple Linear Regression  \n",
            "1  0.282348  0.176731  0.420393  138.904649   Normal       Decision Tree Model  \n",
            "2  0.365720  0.235026  0.484795  173.392079   Normal       Decision Tree Model  \n",
            "3  0.383921  0.255134  0.505108  194.961371   Normal       Decision Tree Model  \n",
            "4  0.131777  0.025915  0.160980   29.441769   Normal  Simple Linear Regression  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_resultsStd.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "-ZrH8bOdAcIz",
        "outputId": "7c2db0d0-3f7d-4361-b1a4-e0db6194d5eb"
      },
      "id": "-ZrH8bOdAcIz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Target                        Model            Train R²   Test R²  \\\n",
              "0   new_price            Linear Regression  0.6297378908089446  0.627819   \n",
              "1   new_price      Random Forest Regressor   0.973289789332776  0.824091   \n",
              "2   new_price            XGBoost Regressor  0.8270074320236708  0.766067   \n",
              "3   new_price  Gradient Boosting Regressor  0.7699284396872543  0.746053   \n",
              "4          PC            Linear Regression   0.973660068974925  0.974082   \n",
              "5          PC      Random Forest Regressor                 1.0  1.000000   \n",
              "6          PC            XGBoost Regressor  0.9999566580170176  0.999957   \n",
              "7          PC  Gradient Boosting Regressor  0.9999999999999998  1.000000   \n",
              "8   new_price                    Base LSTM   0.995441277667468  0.995389   \n",
              "9          PC                    Base LSTM  0.9986385895087232  0.998622   \n",
              "10  new_price                Enhanced LSTM  0.9965799990806332  0.996540   \n",
              "11         PC                Enhanced LSTM  0.9985748807407556  0.998598   \n",
              "12  new_price             Hyper-Tuned LSTM      Neural Network  0.997853   \n",
              "13         PC             Hyper-Tuned LSTM      Neural Network  0.999234   \n",
              "\n",
              "             MAE           MSE          RMSE          MAPE  \\\n",
              "0   4.893183e-01  3.739195e-01  6.114896e-01  2.493082e+02   \n",
              "1   2.823479e-01  1.767307e-01  4.203935e-01  1.389046e+02   \n",
              "2   3.657201e-01  2.350260e-01  4.847948e-01  1.733921e+02   \n",
              "3   3.839207e-01  2.551336e-01  5.051075e-01  1.949614e+02   \n",
              "4   1.317771e-01  2.591456e-02  1.609800e-01  2.944177e+01   \n",
              "5   1.665155e-14  4.991350e-28  2.234133e-14  1.707175e-12   \n",
              "6   6.098938e-03  4.334612e-05  6.583777e-03  6.560287e-01   \n",
              "7   1.221103e-08  2.160188e-16  1.469758e-08  3.735057e-06   \n",
              "8   1.088874e+05  2.124968e+10  1.457727e+05  1.696912e+00   \n",
              "9   6.581006e-01  6.840771e-01  8.270895e-01  1.799154e-01   \n",
              "10  9.888741e+04  1.594297e+10  1.262655e+05  1.586700e+00   \n",
              "11  6.973538e-01  6.957364e-01  8.341082e-01  1.885889e-01   \n",
              "12  9.978148e-01  7.361852e+04  1.006993e+10  1.003490e+05   \n",
              "13  9.992408e-01  4.655119e-01  3.767437e-01  6.137945e-01   \n",
              "\n",
              "              Comments                      Type  \n",
              "0               Normal  Simple Linear Regression  \n",
              "1               Normal       Decision Tree Model  \n",
              "2               Normal       Decision Tree Model  \n",
              "3               Normal       Decision Tree Model  \n",
              "4               Normal  Simple Linear Regression  \n",
              "5               Normal       Decision Tree Model  \n",
              "6               Normal       Decision Tree Model  \n",
              "7               Normal       Decision Tree Model  \n",
              "8         Working Well            Neural Network  \n",
              "9         Working Well            Neural Network  \n",
              "10        Working Well            Neural Network  \n",
              "11        Working Well            Neural Network  \n",
              "12  1.1116973480896348              Working Well  \n",
              "13  0.1271135671204354              Working Well  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb102f86-c82d-4667-9596-9108181db60b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Model</th>\n",
              "      <th>Train R²</th>\n",
              "      <th>Test R²</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.6297378908089446</td>\n",
              "      <td>0.627819</td>\n",
              "      <td>4.893183e-01</td>\n",
              "      <td>3.739195e-01</td>\n",
              "      <td>6.114896e-01</td>\n",
              "      <td>2.493082e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Simple Linear Regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>0.973289789332776</td>\n",
              "      <td>0.824091</td>\n",
              "      <td>2.823479e-01</td>\n",
              "      <td>1.767307e-01</td>\n",
              "      <td>4.203935e-01</td>\n",
              "      <td>1.389046e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new_price</td>\n",
              "      <td>XGBoost Regressor</td>\n",
              "      <td>0.8270074320236708</td>\n",
              "      <td>0.766067</td>\n",
              "      <td>3.657201e-01</td>\n",
              "      <td>2.350260e-01</td>\n",
              "      <td>4.847948e-01</td>\n",
              "      <td>1.733921e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>0.7699284396872543</td>\n",
              "      <td>0.746053</td>\n",
              "      <td>3.839207e-01</td>\n",
              "      <td>2.551336e-01</td>\n",
              "      <td>5.051075e-01</td>\n",
              "      <td>1.949614e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PC</td>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.973660068974925</td>\n",
              "      <td>0.974082</td>\n",
              "      <td>1.317771e-01</td>\n",
              "      <td>2.591456e-02</td>\n",
              "      <td>1.609800e-01</td>\n",
              "      <td>2.944177e+01</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Simple Linear Regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PC</td>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.665155e-14</td>\n",
              "      <td>4.991350e-28</td>\n",
              "      <td>2.234133e-14</td>\n",
              "      <td>1.707175e-12</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PC</td>\n",
              "      <td>XGBoost Regressor</td>\n",
              "      <td>0.9999566580170176</td>\n",
              "      <td>0.999957</td>\n",
              "      <td>6.098938e-03</td>\n",
              "      <td>4.334612e-05</td>\n",
              "      <td>6.583777e-03</td>\n",
              "      <td>6.560287e-01</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PC</td>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>0.9999999999999998</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.221103e-08</td>\n",
              "      <td>2.160188e-16</td>\n",
              "      <td>1.469758e-08</td>\n",
              "      <td>3.735057e-06</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Base LSTM</td>\n",
              "      <td>0.995441277667468</td>\n",
              "      <td>0.995389</td>\n",
              "      <td>1.088874e+05</td>\n",
              "      <td>2.124968e+10</td>\n",
              "      <td>1.457727e+05</td>\n",
              "      <td>1.696912e+00</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PC</td>\n",
              "      <td>Base LSTM</td>\n",
              "      <td>0.9986385895087232</td>\n",
              "      <td>0.998622</td>\n",
              "      <td>6.581006e-01</td>\n",
              "      <td>6.840771e-01</td>\n",
              "      <td>8.270895e-01</td>\n",
              "      <td>1.799154e-01</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Enhanced LSTM</td>\n",
              "      <td>0.9965799990806332</td>\n",
              "      <td>0.996540</td>\n",
              "      <td>9.888741e+04</td>\n",
              "      <td>1.594297e+10</td>\n",
              "      <td>1.262655e+05</td>\n",
              "      <td>1.586700e+00</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PC</td>\n",
              "      <td>Enhanced LSTM</td>\n",
              "      <td>0.9985748807407556</td>\n",
              "      <td>0.998598</td>\n",
              "      <td>6.973538e-01</td>\n",
              "      <td>6.957364e-01</td>\n",
              "      <td>8.341082e-01</td>\n",
              "      <td>1.885889e-01</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Hyper-Tuned LSTM</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>0.997853</td>\n",
              "      <td>9.978148e-01</td>\n",
              "      <td>7.361852e+04</td>\n",
              "      <td>1.006993e+10</td>\n",
              "      <td>1.003490e+05</td>\n",
              "      <td>1.1116973480896348</td>\n",
              "      <td>Working Well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PC</td>\n",
              "      <td>Hyper-Tuned LSTM</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>0.999234</td>\n",
              "      <td>9.992408e-01</td>\n",
              "      <td>4.655119e-01</td>\n",
              "      <td>3.767437e-01</td>\n",
              "      <td>6.137945e-01</td>\n",
              "      <td>0.1271135671204354</td>\n",
              "      <td>Working Well</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb102f86-c82d-4667-9596-9108181db60b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb102f86-c82d-4667-9596-9108181db60b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb102f86-c82d-4667-9596-9108181db60b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62cce24d-e5a7-4e2a-ad23-f1cea13cc669\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62cce24d-e5a7-4e2a-ad23-f1cea13cc669')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62cce24d-e5a7-4e2a-ad23-f1cea13cc669 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "master_resultsStd",
              "summary": "{\n  \"name\": \"master_resultsStd\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"PC\",\n          \"new_price\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Linear Regression\",\n          \"Random Forest Regressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train R\\u00b2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"0.9985748807407556\",\n          \"0.9986385895087232\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test R\\u00b2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12610712539437402,\n        \"min\": 0.6278190814983717,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.9986215353867084,\n          0.9985980410147374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37776.098134816886,\n        \"min\": 1.6651551560501206e-14,\n        \"max\": 108887.3848826808,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6581006444821967,\n          0.6973537654269055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6832726796.212915,\n        \"min\": 4.991350358425817e-28,\n        \"max\": 21249678937.23181,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6840770885751147,\n          0.6957364096928192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2691295858.137718,\n        \"min\": 2.234133021649744e-14,\n        \"max\": 10069927952.24808,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.8270895287543633,\n          0.8341081522757221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAPE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26803.292938159888,\n        \"min\": 1.7071746212814945e-12,\n        \"max\": 100349.03064926976,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.1799154060212126,\n          0.1885889151459236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comments\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Working Well\",\n          \"0.1271135671204354\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Decision Tree Model\",\n          \"Working Well\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the file path in Google Drive\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/Std_Datasetv5.csv'\n",
        "\n",
        "# Read the file into a DataFrame\n",
        "try:\n",
        "    merged_dataset = pd.read_csv(file_path)\n",
        "    print(\"[INFO] File loaded successfully into 'merged_dataset'.\")\n",
        "    print(merged_dataset.head())  # Display the first 5 rows\n",
        "except FileNotFoundError:\n",
        "    print(f\"[ERROR] File not found at '{file_path}'. Please check the file path and try again.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while reading the file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQg33mbrEvIi",
        "outputId": "42e16723-fcb7-471d-b5e7-8929f47b3e56"
      },
      "id": "RQg33mbrEvIi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[INFO] File loaded successfully into 'merged_dataset'.\n",
            "   saleable_area(ft^2)  unit_rate  floor  CPI   PC  IR  MW  M3  SD  UR  ...  \\\n",
            "0                  423      15792   22.0    0  351   3  18  17   0   3  ...   \n",
            "1                  761      15857   12.0    0  351   3  18  17   0   3  ...   \n",
            "2                  320      13717   12.0    0  351   3  18  17   0   3  ...   \n",
            "3                  519      16541   29.0    0  351   3  18  17   0   3  ...   \n",
            "4                  699      14721   24.0    0  351   3  18  17   0   3  ...   \n",
            "\n",
            "   floor_height_floor_16to18  floor_height_floor_19to20  \\\n",
            "0                          0                          0   \n",
            "1                          0                          0   \n",
            "2                          0                          0   \n",
            "3                          0                          0   \n",
            "4                          0                          0   \n",
            "\n",
            "   floor_height_floor_21to25  floor_height_floor_26to30  \\\n",
            "0                          1                          0   \n",
            "1                          0                          0   \n",
            "2                          0                          0   \n",
            "3                          0                          1   \n",
            "4                          1                          0   \n",
            "\n",
            "   floor_height_floor_31to35  floor_height_floor_36to40  \\\n",
            "0                          0                          0   \n",
            "1                          0                          0   \n",
            "2                          0                          0   \n",
            "3                          0                          0   \n",
            "4                          0                          0   \n",
            "\n",
            "   floor_height_floor_41to45  floor_height_floor_46to50  \\\n",
            "0                          0                          0   \n",
            "1                          0                          0   \n",
            "2                          0                          0   \n",
            "3                          0                          0   \n",
            "4                          0                          0   \n",
            "\n",
            "   floor_height_floor_above50  floor_height_floor_house03  \n",
            "0                           0                           0  \n",
            "1                           0                           0  \n",
            "2                           0                           0  \n",
            "3                           0                           0  \n",
            "4                           0                           0  \n",
            "\n",
            "[5 rows x 71 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_dataset.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qHMC-IXWXZX",
        "outputId": "49b6f945-4953-4194-f5a5-9e2124b72c73"
      },
      "id": "5qHMC-IXWXZX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 72663 entries, 0 to 72662\n",
            "Data columns (total 71 columns):\n",
            " #   Column                                          Non-Null Count  Dtype  \n",
            "---  ------                                          --------------  -----  \n",
            " 0   saleable_area(ft^2)                             72663 non-null  int64  \n",
            " 1   unit_rate                                       72663 non-null  int64  \n",
            " 2   floor                                           72663 non-null  float64\n",
            " 3   CPI                                             72663 non-null  int64  \n",
            " 4   PC                                              72663 non-null  int64  \n",
            " 5   IR                                              72663 non-null  int64  \n",
            " 6   MW                                              72663 non-null  int64  \n",
            " 7   M3                                              72663 non-null  int64  \n",
            " 8   SD                                              72663 non-null  int64  \n",
            " 9   UR                                              72663 non-null  int64  \n",
            " 10  GDP                                             72663 non-null  int64  \n",
            " 11  CI                                              72663 non-null  int64  \n",
            " 12  HSI                                             72663 non-null  int64  \n",
            " 13  LTV                                             72663 non-null  int64  \n",
            " 14  HS                                              72663 non-null  int64  \n",
            " 15  SOLD                                            72663 non-null  int64  \n",
            " 16  PG                                              72663 non-null  int64  \n",
            " 17  LS                                              72663 non-null  int64  \n",
            " 18  new_price                                       72663 non-null  int64  \n",
            " 19  district_Central and Western District           72663 non-null  int64  \n",
            " 20  district_HKIsland Eastern District              72663 non-null  int64  \n",
            " 21  district_HKIsland Southern District             72663 non-null  int64  \n",
            " 22  district_Kowloon Kowloon City District          72663 non-null  int64  \n",
            " 23  district_Kowloon Kwun Tong District             72663 non-null  int64  \n",
            " 24  district_Kowloon Sham Shui Po District          72663 non-null  int64  \n",
            " 25  district_Kowloon Wong Tai Sin District          72663 non-null  int64  \n",
            " 26  district_Kowloon Yau Tsim Mong District         72663 non-null  int64  \n",
            " 27  district_Kwai Tsing District                    72663 non-null  int64  \n",
            " 28  district_New Territories East Long Ping Estate  72663 non-null  int64  \n",
            " 29  district_New Territories East North District    72663 non-null  int64  \n",
            " 30  district_New Territories East Sha Tin District  72663 non-null  int64  \n",
            " 31  district_New Territories East Tai Po District   72663 non-null  int64  \n",
            " 32  district_New Territories West Islands District  72663 non-null  int64  \n",
            " 33  district_Tsuen Wan District                     72663 non-null  int64  \n",
            " 34  district_Tuen Mun District                      72663 non-null  int64  \n",
            " 35  district_Wan Chai District                      72663 non-null  int64  \n",
            " 36  district_Yuen Long District                     72663 non-null  int64  \n",
            " 37  region_HK                                       72663 non-null  int64  \n",
            " 38  region_KLN                                      72663 non-null  int64  \n",
            " 39  region_NTEast                                   72663 non-null  int64  \n",
            " 40  region_NTWest                                   72663 non-null  int64  \n",
            " 41  floor_size_compact600800                        72663 non-null  int64  \n",
            " 42  floor_size_large10001300                        72663 non-null  int64  \n",
            " 43  floor_size_medium8001000                        72663 non-null  int64  \n",
            " 44  floor_size_micro200400                          72663 non-null  int64  \n",
            " 45  floor_size_nano0200                             72663 non-null  int64  \n",
            " 46  floor_size_small400600                          72663 non-null  int64  \n",
            " 47  YearQuarter_2021Q1                              72663 non-null  int64  \n",
            " 48  YearQuarter_2021Q2                              72663 non-null  int64  \n",
            " 49  YearQuarter_2021Q3                              72663 non-null  int64  \n",
            " 50  YearQuarter_2021Q4                              72663 non-null  int64  \n",
            " 51  YearQuarter_2022Q1                              72663 non-null  int64  \n",
            " 52  YearQuarter_2022Q2                              72663 non-null  int64  \n",
            " 53  YearQuarter_2022Q3                              72663 non-null  int64  \n",
            " 54  YearQuarter_2022Q4                              72663 non-null  int64  \n",
            " 55  YearQuarter_2023Q1                              72663 non-null  int64  \n",
            " 56  floor_height_floor_03to05                       72663 non-null  int64  \n",
            " 57  floor_height_floor_06to08                       72663 non-null  int64  \n",
            " 58  floor_height_floor_09to10                       72663 non-null  int64  \n",
            " 59  floor_height_floor_11to13                       72663 non-null  int64  \n",
            " 60  floor_height_floor_14to15                       72663 non-null  int64  \n",
            " 61  floor_height_floor_16to18                       72663 non-null  int64  \n",
            " 62  floor_height_floor_19to20                       72663 non-null  int64  \n",
            " 63  floor_height_floor_21to25                       72663 non-null  int64  \n",
            " 64  floor_height_floor_26to30                       72663 non-null  int64  \n",
            " 65  floor_height_floor_31to35                       72663 non-null  int64  \n",
            " 66  floor_height_floor_36to40                       72663 non-null  int64  \n",
            " 67  floor_height_floor_41to45                       72663 non-null  int64  \n",
            " 68  floor_height_floor_46to50                       72663 non-null  int64  \n",
            " 69  floor_height_floor_above50                      72663 non-null  int64  \n",
            " 70  floor_height_floor_house03                      72663 non-null  int64  \n",
            "dtypes: float64(1), int64(70)\n",
            "memory usage: 39.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HYPERPARAMETER TUNING"
      ],
      "metadata": {
        "id": "Zqvb0F4Ttf9b"
      },
      "id": "Zqvb0F4Ttf9b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature matrix (X) and target variables (y)\n",
        "\n",
        "features = merged_dataset.drop(columns=['new_price', 'PC'])\n",
        "targets_Std = merged_dataset[['new_price', 'PC']]\n",
        "\n",
        "X = features.copy()\n",
        "y = targets_Std.copy()"
      ],
      "metadata": {
        "id": "xpb9lCczH_QW"
      },
      "id": "xpb9lCczH_QW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# File paths\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_resultsStd.csv')\n",
        "\n",
        "# Load or initialize master results table\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_resultsStd = pd.read_csv(master_results_file_path)\n",
        "    print(f\"[INFO] Loaded existing master results table from '{master_results_file_path}'.\")\n",
        "else:\n",
        "    master_resultsStd = pd.DataFrame(columns=[\"Target\", \"Model\", \"Type\", \"Train R²\", \"Test R²\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"Comments\"])\n",
        "    print(f\"[INFO] Initialized a new master results table.\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = merged_dataset.drop(columns=['new_price', 'PC'])\n",
        "targets_Std = merged_dataset[['new_price', 'PC']]\n",
        "X = features.copy()\n",
        "y = targets_Std.copy()\n",
        "\n",
        "# Normalize features and targets\n",
        "feature_scaler = StandardScaler()\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "\n",
        "target_scalers = {col: StandardScaler() for col in targets_Std.columns}\n",
        "y_scaled = pd.DataFrame({col: target_scalers[col].fit_transform(targets_Std[[col]]).flatten() for col in targets_Std.columns})\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Subset the dataset for faster tuning\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
        "X_train_sample_lstm = X_train_sample.reshape((X_train_sample.shape[0], 1, X_train_sample.shape[1]))\n",
        "\n",
        "# Define the model-building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        return_sequences = hp.Choice(f'return_sequences_{i+1}', values=[True, False]) if i < (num_layers - 1) else False\n",
        "        model.add(LSTM(\n",
        "            units=hp.Int(f'units_layer_{i+1}', min_value=32, max_value=128, step=32),\n",
        "            activation=hp.Choice('activation', values=['relu', 'tanh', 'sigmoid']),\n",
        "            return_sequences=return_sequences,\n",
        "            recurrent_dropout=hp.Choice(f'recurrent_dropout_{i+1}', values=[0.0, 0.2, 0.3]),\n",
        "            input_shape=(X_train_sample_lstm.shape[1], X_train_sample_lstm.shape[2]) if i == 0 else None\n",
        "        ))\n",
        "        model.add(Dropout(rate=hp.Choice(f'dropout_layer_{i+1}', values=[0.2, 0.3, 0.4])))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd']),\n",
        "        loss=hp.Choice('loss', values=['mse', 'mae', 'huber']),\n",
        "        metrics=['mae']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Initialize tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,  # Increased for a better hyperparameter search\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='lstm_hyper_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Loop through targets (new_price and PC) to dynamically update results\n",
        "for target_name in [\"new_price\", \"PC\"]:\n",
        "    if target_name not in y_train.columns:\n",
        "        raise KeyError(f\"Target column '{target_name}' not found in y_train. Available columns are: {y_train.columns.tolist()}\")\n",
        "\n",
        "    # Train and evaluate the model for the current target\n",
        "    y_train_target_sample = y_train_sample[[target_name]].values\n",
        "\n",
        "    # Loop through different batch sizes and epochs\n",
        "    for batch_size in [32, 64, 128]:\n",
        "        for epochs in [10, 20, 30]:\n",
        "            print(f\"[INFO] Tuning for batch_size={batch_size}, epochs={epochs}\")\n",
        "\n",
        "            # Hyperparameter tuning\n",
        "            tuner.search(\n",
        "                X_train_sample_lstm,\n",
        "                y_train_target_sample,\n",
        "                validation_split=0.1,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=[early_stopping]\n",
        "            )\n",
        "\n",
        "            # Build and train the best model\n",
        "            best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "            best_model = tuner.hypermodel.build(best_hps)\n",
        "            history = best_model.fit(\n",
        "                X_train_lstm,\n",
        "                y_train[[target_name]].values,\n",
        "                validation_data=(X_test_lstm, y_test[[target_name]].values),\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=[early_stopping]\n",
        "            )\n",
        "\n",
        "            # Evaluate the model\n",
        "            train_predictions = best_model.predict(X_train_lstm)\n",
        "            test_predictions = best_model.predict(X_test_lstm)\n",
        "\n",
        "            scaler_y = target_scalers[target_name]\n",
        "            train_predictions_rescaled = scaler_y.inverse_transform(train_predictions)\n",
        "            test_predictions_rescaled = scaler_y.inverse_transform(test_predictions)\n",
        "\n",
        "            y_train_rescaled = scaler_y.inverse_transform(y_train[[target_name]])\n",
        "            y_test_rescaled = scaler_y.inverse_transform(y_test[[target_name]])\n",
        "\n",
        "            train_r2 = r2_score(y_train_rescaled, train_predictions_rescaled)\n",
        "            test_r2 = r2_score(y_test_rescaled, test_predictions_rescaled)\n",
        "            mae = mean_absolute_error(y_test_rescaled, test_predictions_rescaled)\n",
        "            mse = mean_squared_error(y_test_rescaled, test_predictions_rescaled)\n",
        "            rmse = np.sqrt(mse)\n",
        "            mape = np.mean(np.abs((y_test_rescaled - test_predictions_rescaled) / y_test_rescaled)) * 100\n",
        "\n",
        "            # Add results to the master results table\n",
        "            new_results = {\n",
        "                \"Target\": target_name,\n",
        "                \"Model\": \"Hyper-Tuned LSTM\",\n",
        "                \"Type\": \"Neural Network\",\n",
        "                \"Train R²\": train_r2,\n",
        "                \"Test R²\": test_r2,\n",
        "                \"MAE\": mae,\n",
        "                \"MSE\": mse,\n",
        "                \"RMSE\": rmse,\n",
        "                \"MAPE\": mape,\n",
        "                \"Comments\": \"Working Well\" if test_r2 > 0.75 and mape < 10 else \"Needs Improvement\"\n",
        "            }\n",
        "\n",
        "            # Convert new_results to a DataFrame\n",
        "            new_results_df = pd.DataFrame([new_results])\n",
        "\n",
        "            # Check if the target and model already exist in the master results table\n",
        "            existing_row_index = master_resultsStd[\n",
        "                (master_resultsStd[\"Target\"] == new_results[\"Target\"]) & (master_resultsStd[\"Model\"] == new_results[\"Model\"])\n",
        "            ].index\n",
        "\n",
        "            if len(existing_row_index) > 0:\n",
        "                # Update the existing row by replacing its values\n",
        "                master_resultsStd.loc[existing_row_index, :] = new_results_df.iloc[0].values\n",
        "            else:\n",
        "                # Append the new results\n",
        "                master_resultsStd = pd.concat([master_resultsStd, new_results_df], ignore_index=True)\n",
        "\n",
        "# Save updated results\n",
        "master_resultsStd.to_csv(master_results_file_path, index=False)\n",
        "print(f\"[INFO] Updated master results saved to '{master_results_file_path}'.\")\n",
        "\n",
        "# Display the final results table\n",
        "print(\"\\nFinal Master Results Table:\")\n",
        "print(master_resultsStd.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1dUx1L-y8fmx",
        "outputId": "f9f04dd6-117f-4593-b196-731e9288d65a"
      },
      "id": "1dUx1L-y8fmx",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 01s]\n",
            "\n",
            "Best val_loss So Far: 0.008529160171747208\n",
            "Total elapsed time: 00h 36m 38s\n",
            "Epoch 1/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11ms/step - loss: 0.2339 - mae: 0.3243 - val_loss: 0.0056 - val_mae: 0.0550\n",
            "Epoch 2/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0251 - mae: 0.1178 - val_loss: 0.0055 - val_mae: 0.0548\n",
            "Epoch 3/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0197 - mae: 0.1039 - val_loss: 0.0035 - val_mae: 0.0453\n",
            "Epoch 4/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0979 - val_loss: 0.0055 - val_mae: 0.0600\n",
            "Epoch 5/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0167 - mae: 0.0948 - val_loss: 0.0030 - val_mae: 0.0410\n",
            "Epoch 6/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0154 - mae: 0.0911 - val_loss: 0.0045 - val_mae: 0.0513\n",
            "Epoch 7/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0151 - mae: 0.0904 - val_loss: 0.0025 - val_mae: 0.0383\n",
            "Epoch 8/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 12ms/step - loss: 0.0143 - mae: 0.0872 - val_loss: 0.0051 - val_mae: 0.0558\n",
            "Epoch 9/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0865 - val_loss: 0.0054 - val_mae: 0.0522\n",
            "Epoch 10/10\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0848 - val_loss: 0.0031 - val_mae: 0.0447\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "[INFO] Tuning for batch_size=32, epochs=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 0.2452 - mae: 0.3347 - val_loss: 0.0068 - val_mae: 0.0606\n",
            "Epoch 2/20\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0248 - mae: 0.1177 - val_loss: 0.0087 - val_mae: 0.0605\n",
            "Epoch 3/20\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 11ms/step - loss: 0.0194 - mae: 0.1032 - val_loss: 0.0059 - val_mae: 0.0577\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "[INFO] Tuning for batch_size=32, epochs=30\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11ms/step - loss: 0.2276 - mae: 0.3223 - val_loss: 0.0069 - val_mae: 0.0591\n",
            "Epoch 2/30\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - loss: 0.0257 - mae: 0.1199 - val_loss: 0.0055 - val_mae: 0.0559\n",
            "Epoch 3/30\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0197 - mae: 0.1036 - val_loss: 0.0064 - val_mae: 0.0575\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "[INFO] Tuning for batch_size=64, epochs=10\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - loss: 0.3093 - mae: 0.3865 - val_loss: 0.0117 - val_mae: 0.0789\n",
            "Epoch 2/10\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.0308 - mae: 0.1317 - val_loss: 0.0036 - val_mae: 0.0450\n",
            "Epoch 3/10\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0208 - mae: 0.1074 - val_loss: 0.0031 - val_mae: 0.0410\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "[INFO] Tuning for batch_size=64, epochs=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 0.3106 - mae: 0.3909 - val_loss: 0.0122 - val_mae: 0.0830\n",
            "Epoch 2/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0323 - mae: 0.1364 - val_loss: 0.0046 - val_mae: 0.0505\n",
            "Epoch 3/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 0.0213 - mae: 0.1096 - val_loss: 0.0036 - val_mae: 0.0436\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "[INFO] Tuning for batch_size=64, epochs=30\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 0.3141 - mae: 0.3900 - val_loss: 0.0130 - val_mae: 0.0882\n",
            "Epoch 2/30\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - loss: 0.0328 - mae: 0.1371 - val_loss: 0.0041 - val_mae: 0.0481\n",
            "Epoch 3/30\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.0220 - mae: 0.1101 - val_loss: 0.0047 - val_mae: 0.0490\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "[INFO] Tuning for batch_size=128, epochs=10\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.4168 - mae: 0.4676 - val_loss: 0.0189 - val_mae: 0.1025\n",
            "Epoch 2/10\n",
            "\u001b[1m 96/455\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.0483 - mae: 0.1680"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-c284fb16c6b0>\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mbest_hps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             history = best_model.fit(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mX_train_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# File paths\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_resultsStd.csv')\n",
        "\n",
        "# Load or initialize master results table\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_resultsStd = pd.read_csv(master_results_file_path)\n",
        "    print(f\"[INFO] Loaded existing master results table from '{master_results_file_path}'.\")\n",
        "else:\n",
        "    master_resultsStd = pd.DataFrame(columns=[\"Target\", \"Model\", \"Type\", \"Train R²\", \"Test R²\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"Comments\"])\n",
        "    print(f\"[INFO] Initialized a new master results table.\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = merged_dataset.drop(columns=['new_price', 'PC'])\n",
        "targets_Std = merged_dataset[['new_price', 'PC']]\n",
        "X = features.copy()\n",
        "y = targets_Std.copy()\n",
        "\n",
        "# Normalize features and targets\n",
        "feature_scaler = StandardScaler()\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "\n",
        "target_scalers = {col: StandardScaler() for col in targets_Std.columns}\n",
        "y_scaled = pd.DataFrame({col: target_scalers[col].fit_transform(targets_Std[[col]]).flatten() for col in targets_Std.columns})\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Subset the dataset for faster tuning\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
        "X_train_sample_lstm = X_train_sample.reshape((X_train_sample.shape[0], 1, X_train_sample.shape[1]))\n",
        "\n",
        "# Define the model-building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        return_sequences = i < (num_layers - 1)\n",
        "        model.add(LSTM(\n",
        "            units=hp.Int(f'units_layer_{i+1}', min_value=32, max_value=128, step=32),\n",
        "            activation='relu',\n",
        "            return_sequences=return_sequences,\n",
        "            input_shape=(X_train_sample_lstm.shape[1], X_train_sample_lstm.shape[2]) if i == 0 else None\n",
        "        ))\n",
        "        model.add(Dropout(rate=hp.Choice(f'dropout_layer_{i+1}', values=[0.2, 0.3, 0.4])))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
        "    ), loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='lstm_hyper_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Loop through targets (new_price and PC) to dynamically update results\n",
        "for target_name in [\"new_price\", \"PC\"]:\n",
        "    if target_name not in y_train.columns:\n",
        "        raise KeyError(f\"Target column '{target_name}' not found in y_train. Available columns are: {y_train.columns.tolist()}\")\n",
        "\n",
        "    # Train and evaluate the model for the current target\n",
        "    y_train_target_sample = y_train_sample[[target_name]].values\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    tuner.search(\n",
        "        X_train_sample_lstm,\n",
        "        y_train_target_sample,\n",
        "        validation_split=0.1,\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Build and train the best model\n",
        "    best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "    best_model = tuner.hypermodel.build(best_hps)\n",
        "    history = best_model.fit(\n",
        "        X_train_lstm,\n",
        "        y_train[[target_name]].values,\n",
        "        validation_data=(X_test_lstm, y_test[[target_name]].values),\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    train_predictions = best_model.predict(X_train_lstm)\n",
        "    test_predictions = best_model.predict(X_test_lstm)\n",
        "\n",
        "    scaler_y = target_scalers[target_name]\n",
        "    train_predictions_rescaled = scaler_y.inverse_transform(train_predictions)\n",
        "    test_predictions_rescaled = scaler_y.inverse_transform(test_predictions)\n",
        "\n",
        "    y_train_rescaled = scaler_y.inverse_transform(y_train[[target_name]])\n",
        "    y_test_rescaled = scaler_y.inverse_transform(y_test[[target_name]])\n",
        "\n",
        "    train_r2 = r2_score(y_train_rescaled, train_predictions_rescaled)\n",
        "    test_r2 = r2_score(y_test_rescaled, test_predictions_rescaled)\n",
        "    mae = mean_absolute_error(y_test_rescaled, test_predictions_rescaled)\n",
        "    mse = mean_squared_error(y_test_rescaled, test_predictions_rescaled)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = np.mean(np.abs((y_test_rescaled - test_predictions_rescaled) / y_test_rescaled)) * 100\n",
        "\n",
        "    # Add results to the master results table\n",
        "    new_results = {\n",
        "        \"Target\": target_name,\n",
        "        \"Model\": \"Hyper-Tuned LSTM\",\n",
        "        \"Type\": \"Neural Network\",\n",
        "        \"Train R²\": train_r2,\n",
        "        \"Test R²\": test_r2,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAPE\": mape,\n",
        "        \"Comments\": \"Working Well\" if test_r2 > 0.75 and mape < 10 else \"Needs Improvement\"\n",
        "    }\n",
        "\n",
        "    # Convert new_results to a DataFrame\n",
        "    new_results_df = pd.DataFrame([new_results])\n",
        "\n",
        "    # Check if the target and model already exist in the master results table\n",
        "    existing_row_index = master_resultsStd[\n",
        "        (master_resultsStd[\"Target\"] == new_results[\"Target\"]) & (master_resultsStd[\"Model\"] == new_results[\"Model\"])\n",
        "    ].index\n",
        "\n",
        "    if len(existing_row_index) > 0:\n",
        "        # Update the existing row by replacing its values\n",
        "        master_resultsStd.loc[existing_row_index, :] = new_results_df.iloc[0].values\n",
        "    else:\n",
        "        # Append the new results\n",
        "        master_resultsStd = pd.concat([master_resultsStd, new_results_df], ignore_index=True)\n",
        "\n",
        "# Save updated results\n",
        "master_resultsStd.to_csv(master_results_file_path, index=False)\n",
        "print(f\"[INFO] Updated master results saved to '{master_results_file_path}'.\")\n",
        "\n",
        "# Display the final results table\n",
        "print(\"\\nFinal Master Results Table:\")\n",
        "print(master_resultsStd.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y415zZ7aIXj8",
        "outputId": "ea400a40-ad8d-4ca8-ef14-0c3667c54498"
      },
      "id": "y415zZ7aIXj8",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded existing master results table from '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/master_resultsStd.csv'.\n",
            "Reloading Tuner from hyperparam_tuning/lstm_hyper_tuning/tuner0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - loss: 0.3721 - val_loss: 0.0169\n",
            "Epoch 2/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0705 - val_loss: 0.0101\n",
            "Epoch 3/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0567 - val_loss: 0.0069\n",
            "Epoch 4/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0533 - val_loss: 0.0089\n",
            "Epoch 5/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - loss: 0.0518 - val_loss: 0.0060\n",
            "Epoch 6/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0511 - val_loss: 0.0056\n",
            "Epoch 7/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0514 - val_loss: 0.0092\n",
            "Epoch 8/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0498 - val_loss: 0.0040\n",
            "Epoch 9/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0484 - val_loss: 0.0038\n",
            "Epoch 10/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0487 - val_loss: 0.0042\n",
            "Epoch 11/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0482 - val_loss: 0.0060\n",
            "Epoch 12/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0479 - val_loss: 0.0038\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.2372 - val_loss: 0.0080\n",
            "Epoch 2/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0527 - val_loss: 0.0038\n",
            "Epoch 3/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0462 - val_loss: 0.0037\n",
            "Epoch 4/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 0.0445 - val_loss: 0.0011\n",
            "Epoch 5/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0440 - val_loss: 0.0020\n",
            "Epoch 6/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0439 - val_loss: 0.0029\n",
            "Epoch 7/20\n",
            "\u001b[1m909/909\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0446 - val_loss: 0.0020\n",
            "\u001b[1m1817/1817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "[INFO] Updated master results saved to '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/master_resultsStd.csv'.\n",
            "\n",
            "Final Master Results Table:\n",
            "   Target                       Model           Train R²  Test R²          MAE          MSE         RMSE         MAPE     Comments                     Type\n",
            "new_price           Linear Regression 0.6297378908089446 0.627819 4.893183e-01 3.739195e-01 6.114896e-01 2.493082e+02       Normal Simple Linear Regression\n",
            "new_price     Random Forest Regressor  0.973289789332776 0.824091 2.823479e-01 1.767307e-01 4.203935e-01 1.389046e+02       Normal      Decision Tree Model\n",
            "new_price           XGBoost Regressor 0.8270074320236708 0.766067 3.657201e-01 2.350260e-01 4.847948e-01 1.733921e+02       Normal      Decision Tree Model\n",
            "new_price Gradient Boosting Regressor 0.7699284396872543 0.746053 3.839207e-01 2.551336e-01 5.051075e-01 1.949614e+02       Normal      Decision Tree Model\n",
            "       PC           Linear Regression  0.973660068974925 0.974082 1.317771e-01 2.591456e-02 1.609800e-01 2.944177e+01       Normal Simple Linear Regression\n",
            "       PC     Random Forest Regressor                1.0 1.000000 1.665155e-14 4.991350e-28 2.234133e-14 1.707175e-12       Normal      Decision Tree Model\n",
            "       PC           XGBoost Regressor 0.9999566580170176 0.999957 6.098938e-03 4.334612e-05 6.583777e-03 6.560287e-01       Normal      Decision Tree Model\n",
            "       PC Gradient Boosting Regressor 0.9999999999999998 1.000000 1.221103e-08 2.160188e-16 1.469758e-08 3.735057e-06       Normal      Decision Tree Model\n",
            "new_price                   Base LSTM  0.995441277667468 0.995389 1.088874e+05 2.124968e+10 1.457727e+05 1.696912e+00 Working Well           Neural Network\n",
            "       PC                   Base LSTM 0.9986385895087232 0.998622 6.581006e-01 6.840771e-01 8.270895e-01 1.799154e-01 Working Well           Neural Network\n",
            "new_price               Enhanced LSTM 0.9965799990806332 0.996540 9.888741e+04 1.594297e+10 1.262655e+05 1.586700e+00 Working Well           Neural Network\n",
            "       PC               Enhanced LSTM 0.9985748807407556 0.998598 6.973538e-01 6.957364e-01 8.341082e-01 1.885889e-01 Working Well           Neural Network\n",
            "new_price            Hyper-Tuned LSTM     Neural Network 0.996178 9.961755e-01 9.919789e+04 1.762409e+10 1.327557e+05     1.565611             Working Well\n",
            "       PC            Hyper-Tuned LSTM     Neural Network 0.998858 9.988758e-01 5.946520e-01 5.579006e-01 7.469274e-01     0.163728             Working Well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BEST HYPER TUNED ARCHITECTURE"
      ],
      "metadata": {
        "id": "97OircKVuCij"
      },
      "id": "97OircKVuCij"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the best architecture and hyperparameters from the hyperparameter tuner\n",
        "print(\"[INFO] Best Hyperparameters for the Tuned LSTM Model:\")\n",
        "\n",
        "# Number of layers\n",
        "num_layers = best_hps.get('num_layers')\n",
        "print(f\"Number of Layers: {num_layers}\")\n",
        "\n",
        "# Loop through each layer and display its configuration\n",
        "for i in range(num_layers):\n",
        "    units = best_hps.get(f'units_layer_{i+1}')\n",
        "    dropout = best_hps.get(f'dropout_layer_{i+1}')\n",
        "    recurrent_dropout = best_hps.get(f'recurrent_dropout_{i+1}')\n",
        "    return_sequences = best_hps.get(f'return_sequences_{i+1}') if i < (num_layers - 1) else False\n",
        "    print(f\"Layer {i+1}:\")\n",
        "    print(f\"  Units: {units}\")\n",
        "    print(f\"  Dropout Rate: {dropout}\")\n",
        "    print(f\"  Recurrent Dropout Rate: {recurrent_dropout}\")\n",
        "    print(f\"  Return Sequences: {return_sequences}\")\n",
        "\n",
        "# Activation function\n",
        "activation_function = best_hps.get('activation')\n",
        "print(f\"Activation Function: {activation_function}\")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = best_hps.get('optimizer')\n",
        "print(f\"Optimizer: {optimizer}\")\n",
        "\n",
        "# Loss function\n",
        "loss_function = best_hps.get('loss')\n",
        "print(f\"Loss Function: {loss_function}\")\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = best_hps.get('learning_rate')\n",
        "print(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "# Display manually tuned batch size and epochs\n",
        "print(\"\\n[INFO] Manually Tuned Hyperparameters:\")\n",
        "batch_size = 64  # Replace with the batch size used in the nested loop\n",
        "epochs = 20  # Replace with the epochs used in the nested loop\n",
        "print(f\"Batch Size: {batch_size}\")\n",
        "print(f\"Epochs: {epochs}\")\n",
        "\n",
        "# Alternatively, show a summary of the best model architecture\n",
        "print(\"\\n[INFO] Best Model Architecture:\")\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "wyOD92i2_hrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "outputId": "08606683-95fd-4356-8767-42af4bc6d31f"
      },
      "id": "wyOD92i2_hrh",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Best Hyperparameters for the Tuned LSTM Model:\n",
            "Number of Layers: 3\n",
            "Layer 1:\n",
            "  Units: 64\n",
            "  Dropout Rate: 0.2\n",
            "  Recurrent Dropout Rate: 0.0\n",
            "  Return Sequences: 1\n",
            "Layer 2:\n",
            "  Units: 128\n",
            "  Dropout Rate: 0.2\n",
            "  Recurrent Dropout Rate: 0.0\n",
            "  Return Sequences: 1\n",
            "Layer 3:\n",
            "  Units: 128\n",
            "  Dropout Rate: 0.3\n",
            "  Recurrent Dropout Rate: 0.0\n",
            "  Return Sequences: False\n",
            "Activation Function: relu\n",
            "Optimizer: adam\n",
            "Loss Function: mse\n",
            "Learning Rate: 0.001\n",
            "\n",
            "[INFO] Manually Tuned Hyperparameters:\n",
            "Batch Size: 64\n",
            "Epochs: 20\n",
            "\n",
            "[INFO] Best Model Architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m34,304\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,304</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m794,501\u001b[0m (3.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">794,501</span> (3.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,833\u001b[0m (1.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,833</span> (1.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m529,668\u001b[0m (2.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,668</span> (2.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Install `python-docx` if not already installed\n",
        "try:\n",
        "    from docx import Document\n",
        "except ModuleNotFoundError:\n",
        "    print(\"[INFO] Installing python-docx...\")\n",
        "    !pip install python-docx\n",
        "    from docx import Document\n",
        "\n",
        "# Mount Google Drive (specific to Google Colab)\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"[INFO] Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"[WARNING] Could not mount Google Drive: {e}\")\n",
        "    print(\"[INFO] Ensure this code is running in Google Colab.\")\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Step 1: Save the results of the best hyperparameter-tuned architecture\n",
        "doc = Document()\n",
        "\n",
        "# Add a title to the document\n",
        "doc.add_heading(\"Best Hyperparameter-Tuned Architecture\", level=1)\n",
        "\n",
        "# Add the architecture details to the document\n",
        "doc.add_heading(\"Hyperparameters\", level=2)\n",
        "\n",
        "try:\n",
        "    # Ensure best_hps is defined\n",
        "    if 'best_hps' not in globals():\n",
        "        raise ValueError(\"The variable 'best_hps' is not defined. Ensure hyperparameter tuning is completed.\")\n",
        "\n",
        "    # Add the number of layers\n",
        "    num_layers = best_hps.get('num_layers')\n",
        "    doc.add_paragraph(f\"Number of Layers: {num_layers}\")\n",
        "\n",
        "    # Add details for each layer\n",
        "    for i in range(num_layers):\n",
        "        units = best_hps.get(f'units_layer_{i+1}')\n",
        "        dropout = best_hps.get(f'dropout_layer_{i+1}')\n",
        "        recurrent_dropout = best_hps.get(f'recurrent_dropout_{i+1}')\n",
        "        return_sequences = best_hps.get(f'return_sequences_{i+1}') if i < (num_layers - 1) else False\n",
        "        doc.add_paragraph(f\"Layer {i+1}:\")\n",
        "        doc.add_paragraph(f\"  Units: {units}\")\n",
        "        doc.add_paragraph(f\"  Dropout Rate: {dropout}\")\n",
        "        doc.add_paragraph(f\"  Recurrent Dropout Rate: {recurrent_dropout}\")\n",
        "        doc.add_paragraph(f\"  Return Sequences: {return_sequences}\")\n",
        "\n",
        "    # Add other hyperparameters\n",
        "    activation_function = best_hps.get('activation')\n",
        "    optimizer = best_hps.get('optimizer')\n",
        "    loss_function = best_hps.get('loss')\n",
        "    learning_rate = best_hps.get('learning_rate')\n",
        "\n",
        "    doc.add_paragraph(f\"Activation Function: {activation_function}\")\n",
        "    doc.add_paragraph(f\"Optimizer: {optimizer}\")\n",
        "    doc.add_paragraph(f\"Loss Function: {loss_function}\")\n",
        "    doc.add_paragraph(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "    # Add batch size and epochs (if manually tuned)\n",
        "    batch_size = 64  # Replace with the actual batch size used\n",
        "    epochs = 20  # Replace with the actual epochs used\n",
        "    doc.add_paragraph(f\"Batch Size: {batch_size}\")\n",
        "    doc.add_paragraph(f\"Epochs: {epochs}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while adding hyperparameters to the Word document: {e}\")\n",
        "    raise\n",
        "\n",
        "# Add a placeholder for the model summary\n",
        "try:\n",
        "    if 'best_model' not in globals():\n",
        "        raise ValueError(\"The variable 'best_model' is not defined. Ensure the best model is built after tuning.\")\n",
        "\n",
        "    doc.add_heading(\"Model Architecture Summary\", level=2)\n",
        "\n",
        "    # Capture the model summary as a string\n",
        "    from io import StringIO\n",
        "    import sys\n",
        "    model_summary_io = StringIO()\n",
        "    sys.stdout = model_summary_io  # Redirect stdout to capture the model summary\n",
        "    best_model.summary()\n",
        "    sys.stdout = sys.__stdout__  # Reset stdout to default\n",
        "    model_summary = model_summary_io.getvalue()\n",
        "\n",
        "    # Add the model summary to the Word document\n",
        "    doc.add_paragraph(model_summary)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while adding the model summary to the Word document: {e}\")\n",
        "    raise\n",
        "\n",
        "# Step 4: Save the Word document\n",
        "output_file = os.path.join(subdirectory, 'best_hyper_tuned_architecture.docx')\n",
        "\n",
        "try:\n",
        "    doc.save(output_file)\n",
        "    print(f\"[INFO] Word document saved successfully at '{output_file}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while saving the Word document: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "2hWdnumOAbJ8",
        "outputId": "25a87015-4850-4506-addc-de15c49fb4c0"
      },
      "id": "2hWdnumOAbJ8",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m34,304\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_22 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,304</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m794,501\u001b[0m (3.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">794,501</span> (3.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,833\u001b[0m (1.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,833</span> (1.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m529,668\u001b[0m (2.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,668</span> (2.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[INFO] Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5PblXhjd_oUI"
      },
      "id": "5PblXhjd_oUI"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Install `python-docx` if not already installed\n",
        "try:\n",
        "    from docx import Document\n",
        "except ModuleNotFoundError:\n",
        "    print(\"[INFO] Installing python-docx...\")\n",
        "    !pip install python-docx\n",
        "    from docx import Document\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Step 1: Save the results of the best hyperparameter-tuned architecture\n",
        "doc = Document()\n",
        "\n",
        "# Add a title to the document\n",
        "doc.add_heading(\"Best Hyperparameter-Tuned Architecture\", level=1)\n",
        "\n",
        "# Add the architecture details to the document\n",
        "doc.add_heading(\"Hyperparameters\", level=2)\n",
        "doc.add_paragraph(f\"Number of Layers: {best_hps.get('num_layers')}\")\n",
        "\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    units = best_hps.get(f'units_layer_{i+1}')\n",
        "    dropout = best_hps.get(f'dropout_layer_{i+1}')\n",
        "    doc.add_paragraph(f\"Layer {i+1}: {units} units, Dropout rate: {dropout}\")\n",
        "\n",
        "learning_rate = best_hps.get('learning_rate')\n",
        "doc.add_paragraph(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "# Add a placeholder for the model summary\n",
        "doc.add_heading(\"Model Architecture Summary\", level=2)\n",
        "doc.add_paragraph(\"[INFO] Model Architecture Summary:\")\n",
        "doc.add_paragraph(best_model.summary(print_fn=lambda x: x))\n",
        "\n",
        "# Step 4: Save the Word document\n",
        "output_file = os.path.join(subdirectory, 'best_hyper_tuned_architecture.docx')\n",
        "\n",
        "try:\n",
        "    doc.save(output_file)\n",
        "    print(f\"[INFO] Word document saved successfully at '{output_file}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while saving the Word document: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "fSCPUTV33N5D",
        "outputId": "f81c763a-b0f3-434b-c9af-02a54e5287ac"
      },
      "id": "fSCPUTV33N5D",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Word document saved successfully at '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/best_hyper_tuned_architecture.docx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVING THE RESULTS"
      ],
      "metadata": {
        "id": "dvjrSnWQrKfk"
      },
      "id": "dvjrSnWQrKfk"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Define file path for saving the DataFrame as 'Std_Datasetv6.csv'\n",
        "file_path = os.path.join(subdirectory, 'Std_Datasetv6.csv')\n",
        "\n",
        "# Save the DataFrame to the file path\n",
        "try:\n",
        "    merged_dataset.to_csv(file_path, index=False)\n",
        "    print(f\"[INFO] File 'Std_Datasetv6.csv' saved successfully at '{file_path}'.\")\n",
        "except NameError:\n",
        "    print(\"[ERROR] The DataFrame 'merged_dataset' does not exist. Please define it before saving.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while saving the file: {e}\")"
      ],
      "metadata": {
        "id": "Cd4h9r4G_hwV"
      },
      "id": "Cd4h9r4G_hwV",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Define file path for saving the DataFrame\n",
        "file_path = os.path.join(subdirectory, 'master_resultsStd.csv')  # Change the filename\n",
        "\n",
        "# Save the DataFrame to the file path\n",
        "try:\n",
        "    master_resultsStd.to_csv(file_path, index=False)\n",
        "    print(f\"[INFO] File 'master_resultsStd.csv' saved successfully at '{file_path}'.\")\n",
        "except NameError:\n",
        "    print(\"[ERROR] The DataFrame 'master_resultsStd' does not exist. Please define it before saving.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while saving the file: {e}\")"
      ],
      "metadata": {
        "id": "lRqieURWIq6D"
      },
      "id": "lRqieURWIq6D",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Install `python-docx` if not already installed\n",
        "try:\n",
        "    from docx import Document\n",
        "except ModuleNotFoundError:\n",
        "    print(\"[INFO] Installing python-docx...\")\n",
        "    !pip install python-docx\n",
        "    from docx import Document\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Step 1: Use the existing DataFrame\n",
        "try:\n",
        "    df = master_resultsStd.head(20)  # Use the first 20 rows of the already loaded DataFrame\n",
        "    print(\"[INFO] DataFrame 'master_resultsStd' is already loaded and limited to the first 20 rows.\")\n",
        "except NameError:\n",
        "    print(\"[ERROR] The DataFrame 'master_resultsStd' does not exist. Please ensure it is loaded.\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An unexpected error occurred: {e}\")\n",
        "    raise\n",
        "\n",
        "# Step 2: Create a Word document\n",
        "doc = Document()\n",
        "\n",
        "# Add a title to the document\n",
        "doc.add_heading(\"Master Results Table\", level=1)\n",
        "\n",
        "# Step 3: Add a table to the Word document\n",
        "table = doc.add_table(rows=1, cols=len(df.columns))\n",
        "\n",
        "# Add column headers to the table\n",
        "header_cells = table.rows[0].cells\n",
        "for i, column_name in enumerate(df.columns):\n",
        "    header_cells[i].text = column_name\n",
        "\n",
        "# Add data rows to the table\n",
        "for _, row in df.iterrows():\n",
        "    row_cells = table.add_row().cells\n",
        "    for i, value in enumerate(row):\n",
        "        row_cells[i].text = str(value)\n",
        "\n",
        "# Step 4: Save the Word document to the subdirectory\n",
        "output_file = os.path.join(subdirectory, 'master_resultsStd.doc')  # Save as master_resultsStd.doc\n",
        "\n",
        "try:\n",
        "    doc.save(output_file)\n",
        "    print(f\"[INFO] Word document saved successfully at '{output_file}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while saving the Word document: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "-9g-IbrcI2qc"
      },
      "id": "-9g-IbrcI2qc",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13JrzY1i3E7j"
      },
      "id": "13JrzY1i3E7j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_resultsStd.shape"
      ],
      "metadata": {
        "id": "xvFBqAWu_LOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed95e7e-b078-4318-8ea2-337d731c22b7"
      },
      "id": "xvFBqAWu_LOc",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Define file path for saving the DataFrame\n",
        "file_path = os.path.join(subdirectory, 'master_resultsStd.csv')  # Change the filename\n",
        "\n",
        "# Save the DataFrame to the file path\n",
        "try:\n",
        "    master_resultsStd.to_csv(file_path, index=False)\n",
        "    print(f\"[INFO] File 'master_resultsStd.csv' saved successfully at '{file_path}'.\")\n",
        "except NameError:\n",
        "    print(\"[ERROR] The DataFrame 'master_resultsStd' does not exist. Please define it before saving.\")\n",
        "except Exception as e:\n",
        "    print(f\"[ERROR] An error occurred while saving the file: {e}\")"
      ],
      "metadata": {
        "id": "k3NjXXmkrSdO"
      },
      "id": "k3NjXXmkrSdO",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_dataset.shape"
      ],
      "metadata": {
        "id": "c8tm3qhwrSiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4f3680-dbcc-4d6f-95b4-55035cf9d534"
      },
      "id": "c8tm3qhwrSiP",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72663, 71)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "76e20d30",
      "metadata": {
        "id": "76e20d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "7e23223a-52b5-4031-9eef-0041ac67777d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Target                        Model            Train R²   Test R²  \\\n",
              "0   new_price            Linear Regression  0.6297378908089446  0.627819   \n",
              "1   new_price      Random Forest Regressor   0.973289789332776  0.824091   \n",
              "2   new_price            XGBoost Regressor  0.8270074320236708  0.766067   \n",
              "3   new_price  Gradient Boosting Regressor  0.7699284396872543  0.746053   \n",
              "4          PC            Linear Regression   0.973660068974925  0.974082   \n",
              "5          PC      Random Forest Regressor                 1.0  1.000000   \n",
              "6          PC            XGBoost Regressor  0.9999566580170176  0.999957   \n",
              "7          PC  Gradient Boosting Regressor  0.9999999999999998  1.000000   \n",
              "8   new_price                    Base LSTM   0.995441277667468  0.995389   \n",
              "9          PC                    Base LSTM  0.9986385895087232  0.998622   \n",
              "10  new_price                Enhanced LSTM  0.9965799990806332  0.996540   \n",
              "11         PC                Enhanced LSTM  0.9985748807407556  0.998598   \n",
              "12  new_price             Hyper-Tuned LSTM      Neural Network  0.987344   \n",
              "13         PC             Hyper-Tuned LSTM      Neural Network  0.998858   \n",
              "\n",
              "             MAE           MSE          RMSE          MAPE  \\\n",
              "0   4.893183e-01  3.739195e-01  6.114896e-01  2.493082e+02   \n",
              "1   2.823479e-01  1.767307e-01  4.203935e-01  1.389046e+02   \n",
              "2   3.657201e-01  2.350260e-01  4.847948e-01  1.733921e+02   \n",
              "3   3.839207e-01  2.551336e-01  5.051075e-01  1.949614e+02   \n",
              "4   1.317771e-01  2.591456e-02  1.609800e-01  2.944177e+01   \n",
              "5   1.665155e-14  4.991350e-28  2.234133e-14  1.707175e-12   \n",
              "6   6.098938e-03  4.334612e-05  6.583777e-03  6.560287e-01   \n",
              "7   1.221103e-08  2.160188e-16  1.469758e-08  3.735057e-06   \n",
              "8   1.088874e+05  2.124968e+10  1.457727e+05  1.696912e+00   \n",
              "9   6.581006e-01  6.840771e-01  8.270895e-01  1.799154e-01   \n",
              "10  9.888741e+04  1.594297e+10  1.262655e+05  1.586700e+00   \n",
              "11  6.973538e-01  6.957364e-01  8.341082e-01  1.885889e-01   \n",
              "12  9.870420e-01  1.889060e+05  5.971380e+10  2.443641e+05   \n",
              "13  9.988758e-01  5.946520e-01  5.579006e-01  7.469274e-01   \n",
              "\n",
              "               Comments                      Type  \n",
              "0                Normal  Simple Linear Regression  \n",
              "1                Normal       Decision Tree Model  \n",
              "2                Normal       Decision Tree Model  \n",
              "3                Normal       Decision Tree Model  \n",
              "4                Normal  Simple Linear Regression  \n",
              "5                Normal       Decision Tree Model  \n",
              "6                Normal       Decision Tree Model  \n",
              "7                Normal       Decision Tree Model  \n",
              "8          Working Well            Neural Network  \n",
              "9          Working Well            Neural Network  \n",
              "10         Working Well            Neural Network  \n",
              "11         Working Well            Neural Network  \n",
              "12             3.044235              Working Well  \n",
              "13  0.16372793902931035              Working Well  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09ff4a5e-9363-474d-ad0d-61caeb0c6327\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Model</th>\n",
              "      <th>Train R²</th>\n",
              "      <th>Test R²</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.6297378908089446</td>\n",
              "      <td>0.627819</td>\n",
              "      <td>4.893183e-01</td>\n",
              "      <td>3.739195e-01</td>\n",
              "      <td>6.114896e-01</td>\n",
              "      <td>2.493082e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Simple Linear Regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>0.973289789332776</td>\n",
              "      <td>0.824091</td>\n",
              "      <td>2.823479e-01</td>\n",
              "      <td>1.767307e-01</td>\n",
              "      <td>4.203935e-01</td>\n",
              "      <td>1.389046e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new_price</td>\n",
              "      <td>XGBoost Regressor</td>\n",
              "      <td>0.8270074320236708</td>\n",
              "      <td>0.766067</td>\n",
              "      <td>3.657201e-01</td>\n",
              "      <td>2.350260e-01</td>\n",
              "      <td>4.847948e-01</td>\n",
              "      <td>1.733921e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>0.7699284396872543</td>\n",
              "      <td>0.746053</td>\n",
              "      <td>3.839207e-01</td>\n",
              "      <td>2.551336e-01</td>\n",
              "      <td>5.051075e-01</td>\n",
              "      <td>1.949614e+02</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PC</td>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.973660068974925</td>\n",
              "      <td>0.974082</td>\n",
              "      <td>1.317771e-01</td>\n",
              "      <td>2.591456e-02</td>\n",
              "      <td>1.609800e-01</td>\n",
              "      <td>2.944177e+01</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Simple Linear Regression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PC</td>\n",
              "      <td>Random Forest Regressor</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.665155e-14</td>\n",
              "      <td>4.991350e-28</td>\n",
              "      <td>2.234133e-14</td>\n",
              "      <td>1.707175e-12</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PC</td>\n",
              "      <td>XGBoost Regressor</td>\n",
              "      <td>0.9999566580170176</td>\n",
              "      <td>0.999957</td>\n",
              "      <td>6.098938e-03</td>\n",
              "      <td>4.334612e-05</td>\n",
              "      <td>6.583777e-03</td>\n",
              "      <td>6.560287e-01</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>PC</td>\n",
              "      <td>Gradient Boosting Regressor</td>\n",
              "      <td>0.9999999999999998</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.221103e-08</td>\n",
              "      <td>2.160188e-16</td>\n",
              "      <td>1.469758e-08</td>\n",
              "      <td>3.735057e-06</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Decision Tree Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Base LSTM</td>\n",
              "      <td>0.995441277667468</td>\n",
              "      <td>0.995389</td>\n",
              "      <td>1.088874e+05</td>\n",
              "      <td>2.124968e+10</td>\n",
              "      <td>1.457727e+05</td>\n",
              "      <td>1.696912e+00</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PC</td>\n",
              "      <td>Base LSTM</td>\n",
              "      <td>0.9986385895087232</td>\n",
              "      <td>0.998622</td>\n",
              "      <td>6.581006e-01</td>\n",
              "      <td>6.840771e-01</td>\n",
              "      <td>8.270895e-01</td>\n",
              "      <td>1.799154e-01</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Enhanced LSTM</td>\n",
              "      <td>0.9965799990806332</td>\n",
              "      <td>0.996540</td>\n",
              "      <td>9.888741e+04</td>\n",
              "      <td>1.594297e+10</td>\n",
              "      <td>1.262655e+05</td>\n",
              "      <td>1.586700e+00</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PC</td>\n",
              "      <td>Enhanced LSTM</td>\n",
              "      <td>0.9985748807407556</td>\n",
              "      <td>0.998598</td>\n",
              "      <td>6.973538e-01</td>\n",
              "      <td>6.957364e-01</td>\n",
              "      <td>8.341082e-01</td>\n",
              "      <td>1.885889e-01</td>\n",
              "      <td>Working Well</td>\n",
              "      <td>Neural Network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>new_price</td>\n",
              "      <td>Hyper-Tuned LSTM</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>0.987344</td>\n",
              "      <td>9.870420e-01</td>\n",
              "      <td>1.889060e+05</td>\n",
              "      <td>5.971380e+10</td>\n",
              "      <td>2.443641e+05</td>\n",
              "      <td>3.044235</td>\n",
              "      <td>Working Well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>PC</td>\n",
              "      <td>Hyper-Tuned LSTM</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>0.998858</td>\n",
              "      <td>9.988758e-01</td>\n",
              "      <td>5.946520e-01</td>\n",
              "      <td>5.579006e-01</td>\n",
              "      <td>7.469274e-01</td>\n",
              "      <td>0.16372793902931035</td>\n",
              "      <td>Working Well</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09ff4a5e-9363-474d-ad0d-61caeb0c6327')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09ff4a5e-9363-474d-ad0d-61caeb0c6327 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09ff4a5e-9363-474d-ad0d-61caeb0c6327');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3d3e6e7-5d49-456a-b331-77b1b99ab267\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3d3e6e7-5d49-456a-b331-77b1b99ab267')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3d3e6e7-5d49-456a-b331-77b1b99ab267 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "master_resultsStd",
              "summary": "{\n  \"name\": \"master_resultsStd\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"PC\",\n          \"new_price\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Linear Regression\",\n          \"Random Forest Regressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train R\\u00b2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"0.9985748807407556\",\n          \"0.9986385895087232\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test R\\u00b2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12564112965295413,\n        \"min\": 0.6278190814983717,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.9986215353867084,\n          0.9985980410147374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37776.0984713968,\n        \"min\": 1.6651551560501206e-14,\n        \"max\": 108887.3848826808,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6581006444821967,\n          0.6973537654269055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6832723348.313806,\n        \"min\": 4.991350358425817e-28,\n        \"max\": 21249678937.23181,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6840770885751147,\n          0.6957364096928192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15959179857.468813,\n        \"min\": 2.234133021649744e-14,\n        \"max\": 59713804126.61931,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.8270895287543633,\n          0.8341081522757221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAPE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65292.844911280146,\n        \"min\": 1.7071746212814945e-12,\n        \"max\": 244364.0810893027,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.1799154060212126,\n          0.1885889151459236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comments\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Working Well\",\n          \"0.16372793902931035\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Decision Tree Model\",\n          \"Working Well\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "master_resultsStd.head(20)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ah73YrZPRcSx",
        "Zqvb0F4Ttf9b"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}