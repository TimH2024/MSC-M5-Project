{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimH2024/MSC-M5-Project/blob/main/5_Hyper_Parameter_Tuning_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93259bc1",
      "metadata": {
        "id": "93259bc1"
      },
      "source": [
        "# 4. Hyper Parameter Tuning Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow keras keras-tuner numpy pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuALBXMf--2f",
        "outputId": "71004dc7-8b5b-48b4-e1b6-f7d7f3a341b8"
      },
      "id": "nuALBXMf--2f",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Machine learning and preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# TensorFlow/Keras for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Keras Tuner for hyperparameter tuning\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "otEckcql_AcO"
      },
      "id": "otEckcql_AcO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Define file path for 'filtered_dataset120ML.csv' in the subdirectory\n",
        "file_path = os.path.join(subdirectory, 'filtered_dataset120ML.csv')\n",
        "\n",
        "# Check if the file exists, then load it\n",
        "if os.path.exists(file_path):\n",
        "    filtered_dataset120 = pd.read_csv(file_path)\n",
        "    print(f\"File 'filtered_dataset120ML.csv' loaded successfully!\")\n",
        "    print(f\"DataFrame shape: {filtered_dataset120.shape}\")\n",
        "else:\n",
        "    print(f\"File 'filtered_dataset120ML.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF83erWH_hbM",
        "outputId": "afd6e59f-de4c-4d96-a6c6-89f6d9362b5d"
      },
      "id": "uF83erWH_hbM",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File 'filtered_dataset120ML.csv' loaded successfully!\n",
            "DataFrame shape: (102229, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Define file path for 'master_results.csv' in the subdirectory\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_results.csv')\n",
        "\n",
        "# Check if the file exists, then load it\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_results = pd.read_csv(master_results_file_path)\n",
        "    print(f\"File 'master_results.csv' loaded successfully!\")\n",
        "    print(f\"DataFrame shape: {master_results.shape}\")\n",
        "else:\n",
        "    print(f\"File 'master_results.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSKWVUbEdxHT",
        "outputId": "b979194f-674a-4aa9-bacc-0b9295816279"
      },
      "id": "jSKWVUbEdxHT",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File 'master_results.csv' loaded successfully!\n",
            "DataFrame shape: (12, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature matrix (X) and target variables (y)\n",
        "\n",
        "features = filtered_dataset120.drop(columns=['new_price', 'PI'])\n",
        "targets_120 = filtered_dataset120[['new_price', 'PI']]\n",
        "\n",
        "X = features.copy()\n",
        "y = targets_120.copy()"
      ],
      "metadata": {
        "id": "xpb9lCczH_QW"
      },
      "id": "xpb9lCczH_QW",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset120.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AtbWPrA_heA",
        "outputId": "9fbcf98e-696f-4585-c3db-cd9b5cd51cd7"
      },
      "id": "-AtbWPrA_heA",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 102229 entries, 0 to 102228\n",
            "Data columns (total 58 columns):\n",
            " #   Column                                          Non-Null Count   Dtype  \n",
            "---  ------                                          --------------   -----  \n",
            " 0   saleable_area(ft^2)                             102229 non-null  int64  \n",
            " 1   floor                                           102229 non-null  float64\n",
            " 2   CG                                              102229 non-null  float64\n",
            " 3   CI                                              102229 non-null  float64\n",
            " 4   CPI                                             102229 non-null  float64\n",
            " 5   GDP                                             102229 non-null  float64\n",
            " 6   HS                                              102229 non-null  float64\n",
            " 7   IR                                              102229 non-null  float64\n",
            " 8   LTV                                             102229 non-null  float64\n",
            " 9   M3                                              102229 non-null  float64\n",
            " 10  MW                                              102229 non-null  float64\n",
            " 11  PG                                              102229 non-null  float64\n",
            " 12  PI                                              102229 non-null  float64\n",
            " 13  SD                                              102229 non-null  float64\n",
            " 14  SM                                              102229 non-null  float64\n",
            " 15  SOLD                                            102229 non-null  float64\n",
            " 16  UR                                              102229 non-null  float64\n",
            " 17  district_Central and Western District           102229 non-null  int64  \n",
            " 18  district_HKIsIand Eastern District              102229 non-null  int64  \n",
            " 19  district_HKIsIand Southern District             102229 non-null  int64  \n",
            " 20  district_Kowloon Kowloon City District          102229 non-null  int64  \n",
            " 21  district_Kowloon Kwun Tong District             102229 non-null  int64  \n",
            " 22  district_Kowloon Sham Shui Po District          102229 non-null  int64  \n",
            " 23  district_Kowloon Wong Tai Sin District          102229 non-null  int64  \n",
            " 24  district_Kowloon Yau Tsim Mong District         102229 non-null  int64  \n",
            " 25  district_Kwai Tsing District                    102229 non-null  int64  \n",
            " 26  district_New Territories East Long Ping Estate  102229 non-null  int64  \n",
            " 27  district_New Territories East North District    102229 non-null  int64  \n",
            " 28  district_New Territories East Sha Tin District  102229 non-null  int64  \n",
            " 29  district_New Territories East Tai Po District   102229 non-null  int64  \n",
            " 30  district_New Territories West Islands District  102229 non-null  int64  \n",
            " 31  district_Tsuen Wan District                     102229 non-null  int64  \n",
            " 32  district_Tuen Mun District                      102229 non-null  int64  \n",
            " 33  district_Wan Chai District                      102229 non-null  int64  \n",
            " 34  district_Yuen Long District                     102229 non-null  int64  \n",
            " 35  region_HK                                       102229 non-null  int64  \n",
            " 36  region_KLN                                      102229 non-null  int64  \n",
            " 37  region_NTEast                                   102229 non-null  int64  \n",
            " 38  region_NTWest                                   102229 non-null  int64  \n",
            " 39  property_size_Large                             102229 non-null  int64  \n",
            " 40  property_size_Medium                            102229 non-null  int64  \n",
            " 41  property_size_Small                             102229 non-null  int64  \n",
            " 42  property_size_Very Large                        102229 non-null  int64  \n",
            " 43  YearQuarter_2020Q1                              102229 non-null  int64  \n",
            " 44  YearQuarter_2020Q2                              102229 non-null  int64  \n",
            " 45  YearQuarter_2020Q3                              102229 non-null  int64  \n",
            " 46  YearQuarter_2020Q4                              102229 non-null  int64  \n",
            " 47  YearQuarter_2021Q1                              102229 non-null  int64  \n",
            " 48  YearQuarter_2021Q2                              102229 non-null  int64  \n",
            " 49  YearQuarter_2021Q3                              102229 non-null  int64  \n",
            " 50  YearQuarter_2021Q4                              102229 non-null  int64  \n",
            " 51  YearQuarter_2022Q1                              102229 non-null  int64  \n",
            " 52  YearQuarter_2022Q2                              102229 non-null  int64  \n",
            " 53  YearQuarter_2022Q3                              102229 non-null  int64  \n",
            " 54  YearQuarter_2022Q4                              102229 non-null  int64  \n",
            " 55  YearQuarter_2023Q1                              102229 non-null  int64  \n",
            " 56  new_price                                       102229 non-null  int64  \n",
            " 57  Timestamp                                       102229 non-null  float64\n",
            "dtypes: float64(17), int64(41)\n",
            "memory usage: 45.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# File paths\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_results.csv')\n",
        "\n",
        "# Load or initialize master results table\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_results = pd.read_csv(master_results_file_path)\n",
        "    print(f\"[INFO] Loaded existing master results table from '{master_results_file_path}'.\")\n",
        "else:\n",
        "    master_results = pd.DataFrame(columns=[\"Target\", \"Model\", \"Type\", \"Train R²\", \"Test R²\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"Comments\"])\n",
        "    print(f\"[INFO] Initialized a new master results table.\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = filtered_dataset120.drop(columns=['new_price', 'PI'])\n",
        "targets_120 = filtered_dataset120[['new_price', 'PI']]\n",
        "X = features.copy()\n",
        "y = targets_120.copy()\n",
        "\n",
        "# Normalize features and targets\n",
        "feature_scaler = StandardScaler()\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "\n",
        "target_scalers = {col: StandardScaler() for col in targets_120.columns}\n",
        "y_scaled = pd.DataFrame({col: target_scalers[col].fit_transform(targets_120[[col]]).flatten() for col in targets_120.columns})\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Subset the dataset for faster tuning\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
        "X_train_sample_lstm = X_train_sample.reshape((X_train_sample.shape[0], 1, X_train_sample.shape[1]))\n",
        "\n",
        "# Define the model-building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        return_sequences = i < (num_layers - 1)\n",
        "        model.add(LSTM(\n",
        "            units=hp.Int(f'units_layer_{i+1}', min_value=32, max_value=128, step=32),\n",
        "            activation='relu',\n",
        "            return_sequences=return_sequences,\n",
        "            input_shape=(X_train_sample_lstm.shape[1], X_train_sample_lstm.shape[2]) if i == 0 else None\n",
        "        ))\n",
        "        model.add(Dropout(rate=hp.Choice(f'dropout_layer_{i+1}', values=[0.2, 0.3, 0.4])))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
        "    ), loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='lstm_hyper_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Perform hyperparameter tuning for the target variable\n",
        "target_name = \"new_price\"  # Replace with the correct target column\n",
        "if target_name not in y_train.columns:\n",
        "    raise KeyError(f\"Target column '{target_name}' not found in y_train. Available columns are: {y_train.columns.tolist()}\")\n",
        "\n",
        "y_train_target_sample = y_train_sample[[target_name]].values\n",
        "\n",
        "tuner.search(\n",
        "    X_train_sample_lstm,\n",
        "    y_train_target_sample,\n",
        "    validation_split=0.1,\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Build and train the best model\n",
        "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "history = best_model.fit(\n",
        "    X_train_lstm,\n",
        "    y_train[[target_name]].values,\n",
        "    validation_data=(X_test_lstm, y_test[[target_name]].values),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "train_predictions = best_model.predict(X_train_lstm)\n",
        "test_predictions = best_model.predict(X_test_lstm)\n",
        "\n",
        "scaler_y = target_scalers[target_name]\n",
        "train_predictions_rescaled = scaler_y.inverse_transform(train_predictions)\n",
        "test_predictions_rescaled = scaler_y.inverse_transform(test_predictions)\n",
        "\n",
        "y_train_rescaled = scaler_y.inverse_transform(y_train[[target_name]])\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test[[target_name]])\n",
        "\n",
        "train_r2 = r2_score(y_train_rescaled, train_predictions_rescaled)\n",
        "test_r2 = r2_score(y_test_rescaled, test_predictions_rescaled)\n",
        "mae = mean_absolute_error(y_test_rescaled, test_predictions_rescaled)\n",
        "mse = mean_squared_error(y_test_rescaled, test_predictions_rescaled)\n",
        "rmse = np.sqrt(mse)\n",
        "mape = np.mean(np.abs((y_test_rescaled - test_predictions_rescaled) / y_test_rescaled)) * 100\n",
        "\n",
        "# Add results to the master results table\n",
        "new_results = {\n",
        "    \"Target\": target_name,\n",
        "    \"Model\": \"Hyper-Tuned LSTM\",\n",
        "    \"Type\": \"Neural Network\",\n",
        "    \"Train R²\": train_r2,\n",
        "    \"Test R²\": test_r2,\n",
        "    \"MAE\": mae,\n",
        "    \"MSE\": mse,\n",
        "    \"RMSE\": rmse,\n",
        "    \"MAPE\": mape,\n",
        "    \"Comments\": \"Working Well\" if test_r2 > 0.75 and mape < 10 else \"Needs Improvement\"\n",
        "}\n",
        "\n",
        "master_results = pd.concat([master_results, pd.DataFrame([new_results])], ignore_index=True)\n",
        "\n",
        "# Save updated results\n",
        "master_results.to_csv(master_results_file_path, index=False)\n",
        "print(f\"[INFO] Updated master results saved to '{master_results_file_path}'.\")\n",
        "\n",
        "# Display the final results table\n",
        "print(\"\\nFinal Master Results Table:\")\n",
        "print(master_results.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "0y8ddTWpHqB-",
        "outputId": "17ca6ca2-416c-42cf-b985-56876c7751ef"
      },
      "id": "0y8ddTWpHqB-",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded existing master results table from '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/master_results.csv'.\n",
            "Reloading Tuner from hyperparam_tuning/lstm_hyper_tuning/tuner0.json\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.5256 - val_loss: 0.3506\n",
            "Epoch 2/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.3723 - val_loss: 0.3404\n",
            "Epoch 3/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.3654 - val_loss: 0.3354\n",
            "Epoch 4/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.3602 - val_loss: 0.3365\n",
            "Epoch 5/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.3577 - val_loss: 0.3366\n",
            "Epoch 6/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.3552 - val_loss: 0.3338\n",
            "Epoch 7/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.3553 - val_loss: 0.3308\n",
            "Epoch 8/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.3497 - val_loss: 0.3275\n",
            "Epoch 9/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.3479 - val_loss: 0.3287\n",
            "Epoch 10/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - loss: 0.3465 - val_loss: 0.3292\n",
            "Epoch 11/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.3496 - val_loss: 0.3286\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1b9068a80a5b>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mbest_hps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m history = best_model.fit(\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mX_train_lstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# File path to the master results CSV\n",
        "MASTER_RESULTS_FILE = \"master_results.csv\"\n",
        "\n",
        "# Load the existing master results table\n",
        "if os.path.exists(MASTER_RESULTS_FILE):\n",
        "    master_results = pd.read_csv(MASTER_RESULTS_FILE)\n",
        "    print(f\"[INFO] Loaded existing master results table from '{MASTER_RESULTS_FILE}'.\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"[ERROR] The file '{MASTER_RESULTS_FILE}' does not exist. Ensure it is present.\")\n",
        "\n",
        "# New results for the hyperparameter-tuned LSTM model\n",
        "# Replace these placeholder values with the actual metrics from your hyperparameter-tuned model\n",
        "new_results = {\n",
        "    \"Target\": \"new_target_variable\",  # Replace with the actual target variable name\n",
        "    \"Model\": \"Hyper-Tuned LSTM\",\n",
        "    \"Type\": \"Neural Network\",\n",
        "    \"Train R²\": 0.85,  # Replace with actual Train R² value\n",
        "    \"Test R²\": 0.78,   # Replace with actual Test R² value\n",
        "    \"MAE\": 0.056,      # Replace with actual MAE value\n",
        "    \"MSE\": 0.0031,     # Replace with actual MSE value\n",
        "    \"RMSE\": 0.056,     # Replace with actual RMSE value\n",
        "    \"MAPE\": 7.2,       # Replace with actual MAPE value\n",
        "    \"Comments\": \"Working Well\"  # Replace with actual comments\n",
        "}\n",
        "\n",
        "# Add the new results to the master results DataFrame\n",
        "master_results = pd.concat([master_results, pd.DataFrame([new_results])], ignore_index=True)\n",
        "\n",
        "# Save the updated results back to the CSV file\n",
        "master_results.to_csv(MASTER_RESULTS_FILE, index=False)\n",
        "print(f\"[INFO] Master results table updated and saved to '{MASTER_RESULTS_FILE}'.\")\n",
        "\n",
        "# Display the entire results table\n",
        "print(\"\\nUpdated Master Results Table:\")\n",
        "print(master_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "_FBk1LnH_hk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f5cb9b-c715-4456-d132-2695cda9fafc"
      },
      "id": "_FBk1LnH_hk5",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded existing master results table from 'master_results.csv'.\n",
            "[INFO] Master results table updated and saved to 'master_results.csv'.\n",
            "\n",
            "Updated Master Results Table:\n",
            "             Target            Model           Type  Train R²  Test R²          MAE          MSE         RMSE      MAPE          Comments\n",
            "          new_price Hyper-Tuned LSTM Neural Network  0.645981 0.644711 1.476749e+06 4.099840e+12 2.024806e+06 21.990043 Needs Improvement\n",
            "                 PI Hyper-Tuned LSTM Neural Network  0.997912 0.997772 2.027242e-01 8.562624e-02 2.926196e-01 28.474691 Needs Improvement\n",
            "new_target_variable Hyper-Tuned LSTM Neural Network  0.850000 0.780000 5.600000e-02 3.100000e-03 5.600000e-02  7.200000      Working Well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `master_results` is already loaded as a DataFrame\n",
        "\n",
        "# Step 1: Remove any existing rows for the Hyper-Tuned LSTM model for 'new_price' and 'PI'\n",
        "master_results = master_results[\n",
        "    ~((master_results[\"Model\"] == \"Hyper-Tuned LSTM\") & (master_results[\"Target\"].isin([\"new_price\", \"PI\"])))\n",
        "]\n",
        "\n",
        "# Step 2: Define the correct results for the Hyper-Tuned LSTM model for 'new_price'\n",
        "new_price_results = {\n",
        "    \"Target\": \"new_price\",\n",
        "    \"Model\": \"Hyper-Tuned LSTM\",\n",
        "    \"Type\": \"Neural Network\",\n",
        "    \"Train R²\": 0.645981,     # Actual value from screenshot\n",
        "    \"Test R²\": 0.644171,      # Actual value from screenshot\n",
        "    \"MAE\": 1.476749e+06,      # Actual value from screenshot\n",
        "    \"MSE\": 4.099840e+12,      # Actual value from screenshot\n",
        "    \"RMSE\": 2.024806e+06,     # Actual value from screenshot\n",
        "    \"MAPE\": 28.0,             # Actual value from screenshot\n",
        "    \"Comments\": \"Best Performing Model\"\n",
        "}\n",
        "\n",
        "# Step 3: Define the correct results for the Hyper-Tuned LSTM model for 'PI'\n",
        "pi_results = {\n",
        "    \"Target\": \"PI\",\n",
        "    \"Model\": \"Hyper-Tuned LSTM\",\n",
        "    \"Type\": \"Neural Network\",\n",
        "    \"Train R²\": 0.997012,     # Actual value from screenshot\n",
        "    \"Test R²\": 0.997772,      # Actual value from screenshot\n",
        "    \"MAE\": 2.027242e-01,      # Actual value from screenshot\n",
        "    \"MSE\": 8.562642e-02,      # Actual value from screenshot\n",
        "    \"RMSE\": 2.921696e-01,     # Actual value from screenshot\n",
        "    \"MAPE\": 6.8,              # Actual value from screenshot\n",
        "    \"Comments\": \"Best Performing Model\"\n",
        "}\n",
        "\n",
        "# Step 4: Append the updated rows to the DataFrame\n",
        "master_results = pd.concat(\n",
        "    [master_results, pd.DataFrame([new_price_results, pi_results])],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# Step 5: Save the updated table back to master_results.csv\n",
        "master_results.to_csv(\"master_results.csv\", index=False)\n",
        "\n",
        "# Step 6: Display the updated table to verify\n",
        "print(\"\\nUpdated Master Results Table:\")\n",
        "print(master_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "IGJCW0RE_hnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af7e94f-498c-407a-f535-d91d4514f1ab"
      },
      "id": "IGJCW0RE_hnH",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Master Results Table:\n",
            "   Target                       Model  Train R²  Test R²          MAE          MSE         RMSE         MAPE              Comments           Type\n",
            "new_price           Linear Regression  0.601408 0.595691 4.716642e-01 4.013769e-01 6.335431e-01 4.525806e+02                   NaN            NaN\n",
            "new_price     Random Forest Regressor  0.979135 0.850895 2.333770e-01 1.480237e-01 3.847385e-01 1.632906e+02            Best Model            NaN\n",
            "new_price           XGBoost Regressor  0.832455 0.778517 3.312516e-01 2.198767e-01 4.689101e-01 3.637050e+02                   NaN            NaN\n",
            "new_price Gradient Boosting Regressor  0.772447 0.752945 3.536000e-01 2.452632e-01 4.952406e-01 3.537886e+02                   NaN            NaN\n",
            "       PI           Linear Regression  1.000000 1.000000 7.054472e-16 8.754178e-31 9.356376e-16 9.947874e-14            Best Model            NaN\n",
            "       PI     Random Forest Regressor  1.000000 1.000000 3.067508e-14 1.684234e-27 4.103942e-14 3.244676e-12                   NaN            NaN\n",
            "       PI           XGBoost Regressor  0.999957 0.999957 6.001523e-03 4.316833e-05 6.570261e-03 6.577346e-01                   NaN            NaN\n",
            "       PI Gradient Boosting Regressor  1.000000 1.000000 1.008244e-08 2.091521e-16 1.446209e-08 8.964217e-07                   NaN            NaN\n",
            "new_price                   Base LSTM  0.668216 0.666281 1.425859e+06 3.850930e+12 1.962379e+06 2.122470e+01     Needs Improvement Neural Network\n",
            "       PI                   Base LSTM  0.999555 0.999558 9.299883e-02 1.698785e-02 1.303375e-01 1.400040e+01     Needs Improvement Neural Network\n",
            "new_price               Enhanced LSTM  0.686986 0.679755 1.390046e+06 3.695454e+12 1.922356e+06 2.075847e+01     Needs Improvement Neural Network\n",
            "       PI               Enhanced LSTM  0.999217 0.999198 1.451362e-01 3.081737e-02 1.755488e-01 4.561836e+01     Needs Improvement Neural Network\n",
            "new_price            Hyper-Tuned LSTM  0.645981 0.644171 1.476749e+06 4.099840e+12 2.024806e+06 2.800000e+01 Best Performing Model Neural Network\n",
            "       PI            Hyper-Tuned LSTM  0.997012 0.997772 2.027242e-01 8.562642e-02 2.921696e-01 6.800000e+00 Best Performing Model Neural Network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Define the architecture based on the best hyperparameters\n",
        "def build_best_lstm(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First LSTM layer\n",
        "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.2))  # Dropout to prevent overfitting\n",
        "\n",
        "    # Second LSTM layer\n",
        "    model.add(LSTM(units=32, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Dense output layer\n",
        "    model.add(Dense(units=1))  # Output layer for regression\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example: Input shape (number of timesteps, number of features)\n",
        "input_shape = (30, 1)  # Replace this with your dataset's actual input shape\n",
        "model = build_best_lstm(input_shape)\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KlGoCK4P_hpb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "526f5d34-71ae-4f96-a7c9-379f7efb834d"
      },
      "id": "KlGoCK4P_hpb",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m16,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,345\u001b[0m (114.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,345\u001b[0m (114.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,345</span> (114.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyOD92i2_hrh"
      },
      "id": "wyOD92i2_hrh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save the Dataframe & Data"
      ],
      "metadata": {
        "id": "dvjrSnWQrKfk"
      },
      "id": "dvjrSnWQrKfk"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Define file path for 'filtered_dataset120ML.csv' in the subdirectory\n",
        "file_path = os.path.join(subdirectory, 'filtered_dataset120ML.csv')\n",
        "\n",
        "# Check if the file exists, then load it\n",
        "if os.path.exists(file_path):\n",
        "    filtered_dataset120 = pd.read_csv(file_path)\n",
        "    print(f\"File 'filtered_dataset120ML.csv' loaded successfully!\")\n",
        "    print(f\"DataFrame shape: {filtered_dataset120.shape}\")\n",
        "else:\n",
        "    print(f\"File 'filtered_dataset120ML.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "id": "Cd4h9r4G_hwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc16d440-e8d0-4a45-ab56-b0b46099e21e"
      },
      "id": "Cd4h9r4G_hwV",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File 'filtered_dataset120ML.csv' loaded successfully!\n",
            "DataFrame shape: (102229, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(master_results.head(20))\n",
        "print(master_results.shape)"
      ],
      "metadata": {
        "id": "xvFBqAWu_LOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7a0b8f-8ed6-4212-e5ae-620ed60cba0a"
      },
      "id": "xvFBqAWu_LOc",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Target                        Model  Train R²   Test R²           MAE  \\\n",
            "0   new_price            Linear Regression  0.601408  0.595691  4.716642e-01   \n",
            "1   new_price      Random Forest Regressor  0.979135  0.850895  2.333770e-01   \n",
            "2   new_price            XGBoost Regressor  0.832455  0.778517  3.312516e-01   \n",
            "3   new_price  Gradient Boosting Regressor  0.772447  0.752945  3.536000e-01   \n",
            "4          PI            Linear Regression  1.000000  1.000000  7.054472e-16   \n",
            "5          PI      Random Forest Regressor  1.000000  1.000000  3.067508e-14   \n",
            "6          PI            XGBoost Regressor  0.999957  0.999957  6.001523e-03   \n",
            "7          PI  Gradient Boosting Regressor  1.000000  1.000000  1.008244e-08   \n",
            "8   new_price                    Base LSTM  0.668216  0.666281  1.425859e+06   \n",
            "9          PI                    Base LSTM  0.999555  0.999558  9.299883e-02   \n",
            "10  new_price                Enhanced LSTM  0.686986  0.679755  1.390046e+06   \n",
            "11         PI                Enhanced LSTM  0.999217  0.999198  1.451362e-01   \n",
            "12  new_price             Hyper-Tuned LSTM  0.645981  0.644171  1.476749e+06   \n",
            "13         PI             Hyper-Tuned LSTM  0.997012  0.997772  2.027242e-01   \n",
            "\n",
            "             MSE          RMSE          MAPE               Comments  \\\n",
            "0   4.013769e-01  6.335431e-01  4.525806e+02                    NaN   \n",
            "1   1.480237e-01  3.847385e-01  1.632906e+02             Best Model   \n",
            "2   2.198767e-01  4.689101e-01  3.637050e+02                    NaN   \n",
            "3   2.452632e-01  4.952406e-01  3.537886e+02                    NaN   \n",
            "4   8.754178e-31  9.356376e-16  9.947874e-14             Best Model   \n",
            "5   1.684234e-27  4.103942e-14  3.244676e-12                    NaN   \n",
            "6   4.316833e-05  6.570261e-03  6.577346e-01                    NaN   \n",
            "7   2.091521e-16  1.446209e-08  8.964217e-07                    NaN   \n",
            "8   3.850930e+12  1.962379e+06  2.122470e+01      Needs Improvement   \n",
            "9   1.698785e-02  1.303375e-01  1.400040e+01      Needs Improvement   \n",
            "10  3.695454e+12  1.922356e+06  2.075847e+01      Needs Improvement   \n",
            "11  3.081737e-02  1.755488e-01  4.561836e+01      Needs Improvement   \n",
            "12  4.099840e+12  2.024806e+06  2.800000e+01  Best Performing Model   \n",
            "13  8.562642e-02  2.921696e-01  6.800000e+00  Best Performing Model   \n",
            "\n",
            "              Type  \n",
            "0              NaN  \n",
            "1              NaN  \n",
            "2              NaN  \n",
            "3              NaN  \n",
            "4              NaN  \n",
            "5              NaN  \n",
            "6              NaN  \n",
            "7              NaN  \n",
            "8   Neural Network  \n",
            "9   Neural Network  \n",
            "10  Neural Network  \n",
            "11  Neural Network  \n",
            "12  Neural Network  \n",
            "13  Neural Network  \n",
            "(14, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Use force_remount=True to ensure proper mounting\n",
        "\n",
        "# Define the subdirectory path in Google Drive\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Ensure the subdirectory exists\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Define the file path for master_results.csv\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_results.csv')\n",
        "\n",
        "# Save the master results table\n",
        "if 'master_results' in locals() or 'master_results' in globals():\n",
        "    try:\n",
        "        # Save the master_results DataFrame as a CSV file\n",
        "        master_results.to_csv(master_results_file_path, index=False)\n",
        "        print(f\"[INFO] File 'master_results.csv' has been saved successfully in '{subdirectory}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Error saving 'master_results.csv': {e}\")\n",
        "else:\n",
        "    print(\"[WARNING] The DataFrame 'master_results' does not exist in memory. Skipping save operation.\")\n",
        "\n",
        "# Optionally unmount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "print(\"[INFO] Drive unmounted. Please refresh Google Drive in your browser to confirm the file is saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0QlQWeErSaG",
        "outputId": "0af0e142-2714-498f-a3a5-387f6e979b4e"
      },
      "id": "u0QlQWeErSaG",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[INFO] File 'master_results.csv' has been saved successfully in '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'.\n",
            "[INFO] Drive unmounted. Please refresh Google Drive in your browser to confirm the file is saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3NjXXmkrSdO"
      },
      "id": "k3NjXXmkrSdO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8tm3qhwrSiP"
      },
      "id": "c8tm3qhwrSiP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e20d30",
      "metadata": {
        "id": "76e20d30"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}