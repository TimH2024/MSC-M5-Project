{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimH2024/MSC-M5-Project/blob/main/5_Hyper_Parameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93259bc1",
      "metadata": {
        "id": "93259bc1"
      },
      "source": [
        "# 4. Hyper Parameter Tuning Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow keras keras-tuner numpy pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuALBXMf--2f",
        "outputId": "f2c3c382-aa46-4b11-bb45-07d69dbb8bfb"
      },
      "id": "nuALBXMf--2f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Machine learning and preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# TensorFlow/Keras for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Keras Tuner for hyperparameter tuning\n",
        "from keras_tuner import HyperModel\n",
        "from keras_tuner.tuners import RandomSearch"
      ],
      "metadata": {
        "id": "otEckcql_AcO"
      },
      "id": "otEckcql_AcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Define file path for 'filtered_dataset120ML.csv' in the subdirectory\n",
        "file_path = os.path.join(subdirectory, 'filtered_dataset120ML.csv')\n",
        "\n",
        "# Check if the file exists, then load it\n",
        "if os.path.exists(file_path):\n",
        "    filtered_dataset120 = pd.read_csv(file_path)\n",
        "    print(f\"File 'filtered_dataset120ML.csv' loaded successfully!\")\n",
        "    print(f\"DataFrame shape: {filtered_dataset120.shape}\")\n",
        "else:\n",
        "    print(f\"File 'filtered_dataset120ML.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF83erWH_hbM",
        "outputId": "01de8dce-d790-4102-9e42-335cb1e6f9d1"
      },
      "id": "uF83erWH_hbM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File 'filtered_dataset120ML.csv' loaded successfully!\n",
            "DataFrame shape: (102229, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Define file path for 'master_results.csv' in the subdirectory\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_results.csv')\n",
        "\n",
        "# Check if the file exists, then load it\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_results = pd.read_csv(master_results_file_path)\n",
        "    print(f\"File 'master_results.csv' loaded successfully!\")\n",
        "    print(f\"DataFrame shape: {master_results.shape}\")\n",
        "else:\n",
        "    print(f\"File 'master_results.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSKWVUbEdxHT",
        "outputId": "7b10a120-c384-490c-a417-55c1cb257329"
      },
      "id": "jSKWVUbEdxHT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File 'master_results.csv' loaded successfully!\n",
            "DataFrame shape: (16, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(master_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNE2OscrqgPS",
        "outputId": "171f67bc-2b47-4a65-bb15-1e73ce06cf86"
      },
      "id": "YNE2OscrqgPS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Target                        Model  Train R²   Test R²           MAE  \\\n",
            "0   new_price            Linear Regression  0.601408  0.595691  4.716642e-01   \n",
            "1   new_price      Random Forest Regressor  0.979135  0.850895  2.333770e-01   \n",
            "2   new_price            XGBoost Regressor  0.832455  0.778517  3.312516e-01   \n",
            "3   new_price  Gradient Boosting Regressor  0.772447  0.752945  3.536000e-01   \n",
            "4          PI            Linear Regression  1.000000  1.000000  7.054472e-16   \n",
            "5          PI      Random Forest Regressor  1.000000  1.000000  3.067508e-14   \n",
            "6          PI            XGBoost Regressor  0.999957  0.999957  6.001523e-03   \n",
            "7          PI  Gradient Boosting Regressor  1.000000  1.000000  1.008244e-08   \n",
            "8   new_price                    Base LSTM  0.668216  0.666281  1.425859e+06   \n",
            "9          PI                    Base LSTM  0.999555  0.999558  9.299883e-02   \n",
            "10  new_price                Enhanced LSTM  0.686986  0.679755  1.390046e+06   \n",
            "11         PI                Enhanced LSTM  0.999217  0.999198  1.451362e-01   \n",
            "12  new_price             Hyper-Tuned LSTM  0.645981  0.644171  1.476749e+06   \n",
            "13         PI             Hyper-Tuned LSTM  0.997012  0.997772  2.027242e-01   \n",
            "14  new_price             Hyper-Tuned LSTM  0.681503  0.675983  1.403522e+06   \n",
            "\n",
            "             MSE          RMSE          MAPE               Comments  \\\n",
            "0   4.013769e-01  6.335431e-01  4.525806e+02                    NaN   \n",
            "1   1.480237e-01  3.847385e-01  1.632906e+02             Best Model   \n",
            "2   2.198767e-01  4.689101e-01  3.637050e+02                    NaN   \n",
            "3   2.452632e-01  4.952406e-01  3.537886e+02                    NaN   \n",
            "4   8.754178e-31  9.356376e-16  9.947874e-14             Best Model   \n",
            "5   1.684234e-27  4.103942e-14  3.244676e-12                    NaN   \n",
            "6   4.316833e-05  6.570261e-03  6.577346e-01                    NaN   \n",
            "7   2.091521e-16  1.446209e-08  8.964217e-07                    NaN   \n",
            "8   3.850930e+12  1.962379e+06  2.122470e+01      Needs Improvement   \n",
            "9   1.698785e-02  1.303375e-01  1.400040e+01      Needs Improvement   \n",
            "10  3.695454e+12  1.922356e+06  2.075847e+01      Needs Improvement   \n",
            "11  3.081737e-02  1.755488e-01  4.561836e+01      Needs Improvement   \n",
            "12  4.099840e+12  2.024806e+06  2.800000e+01  Best Performing Model   \n",
            "13  8.562642e-02  2.921696e-01  6.800000e+00  Best Performing Model   \n",
            "14  3.738976e+12  1.933643e+06  2.124625e+01      Needs Improvement   \n",
            "\n",
            "              Type  \n",
            "0              NaN  \n",
            "1              NaN  \n",
            "2              NaN  \n",
            "3              NaN  \n",
            "4              NaN  \n",
            "5              NaN  \n",
            "6              NaN  \n",
            "7              NaN  \n",
            "8   Neural Network  \n",
            "9   Neural Network  \n",
            "10  Neural Network  \n",
            "11  Neural Network  \n",
            "12  Neural Network  \n",
            "13  Neural Network  \n",
            "14  Neural Network  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the feature matrix (X) and target variables (y)\n",
        "\n",
        "features = filtered_dataset120.drop(columns=['new_price', 'PI'])\n",
        "targets_120 = filtered_dataset120[['new_price', 'PI']]\n",
        "\n",
        "X = features.copy()\n",
        "y = targets_120.copy()"
      ],
      "metadata": {
        "id": "xpb9lCczH_QW"
      },
      "id": "xpb9lCczH_QW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset120.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AtbWPrA_heA",
        "outputId": "3569c6e8-4d6d-411a-cf14-7c488dbbf025"
      },
      "id": "-AtbWPrA_heA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 102229 entries, 0 to 102228\n",
            "Data columns (total 58 columns):\n",
            " #   Column                                          Non-Null Count   Dtype  \n",
            "---  ------                                          --------------   -----  \n",
            " 0   saleable_area(ft^2)                             102229 non-null  int64  \n",
            " 1   floor                                           102229 non-null  float64\n",
            " 2   CG                                              102229 non-null  float64\n",
            " 3   CI                                              102229 non-null  float64\n",
            " 4   CPI                                             102229 non-null  float64\n",
            " 5   GDP                                             102229 non-null  float64\n",
            " 6   HS                                              102229 non-null  float64\n",
            " 7   IR                                              102229 non-null  float64\n",
            " 8   LTV                                             102229 non-null  float64\n",
            " 9   M3                                              102229 non-null  float64\n",
            " 10  MW                                              102229 non-null  float64\n",
            " 11  PG                                              102229 non-null  float64\n",
            " 12  PI                                              102229 non-null  float64\n",
            " 13  SD                                              102229 non-null  float64\n",
            " 14  SM                                              102229 non-null  float64\n",
            " 15  SOLD                                            102229 non-null  float64\n",
            " 16  UR                                              102229 non-null  float64\n",
            " 17  district_Central and Western District           102229 non-null  int64  \n",
            " 18  district_HKIsIand Eastern District              102229 non-null  int64  \n",
            " 19  district_HKIsIand Southern District             102229 non-null  int64  \n",
            " 20  district_Kowloon Kowloon City District          102229 non-null  int64  \n",
            " 21  district_Kowloon Kwun Tong District             102229 non-null  int64  \n",
            " 22  district_Kowloon Sham Shui Po District          102229 non-null  int64  \n",
            " 23  district_Kowloon Wong Tai Sin District          102229 non-null  int64  \n",
            " 24  district_Kowloon Yau Tsim Mong District         102229 non-null  int64  \n",
            " 25  district_Kwai Tsing District                    102229 non-null  int64  \n",
            " 26  district_New Territories East Long Ping Estate  102229 non-null  int64  \n",
            " 27  district_New Territories East North District    102229 non-null  int64  \n",
            " 28  district_New Territories East Sha Tin District  102229 non-null  int64  \n",
            " 29  district_New Territories East Tai Po District   102229 non-null  int64  \n",
            " 30  district_New Territories West Islands District  102229 non-null  int64  \n",
            " 31  district_Tsuen Wan District                     102229 non-null  int64  \n",
            " 32  district_Tuen Mun District                      102229 non-null  int64  \n",
            " 33  district_Wan Chai District                      102229 non-null  int64  \n",
            " 34  district_Yuen Long District                     102229 non-null  int64  \n",
            " 35  region_HK                                       102229 non-null  int64  \n",
            " 36  region_KLN                                      102229 non-null  int64  \n",
            " 37  region_NTEast                                   102229 non-null  int64  \n",
            " 38  region_NTWest                                   102229 non-null  int64  \n",
            " 39  property_size_Large                             102229 non-null  int64  \n",
            " 40  property_size_Medium                            102229 non-null  int64  \n",
            " 41  property_size_Small                             102229 non-null  int64  \n",
            " 42  property_size_Very Large                        102229 non-null  int64  \n",
            " 43  YearQuarter_2020Q1                              102229 non-null  int64  \n",
            " 44  YearQuarter_2020Q2                              102229 non-null  int64  \n",
            " 45  YearQuarter_2020Q3                              102229 non-null  int64  \n",
            " 46  YearQuarter_2020Q4                              102229 non-null  int64  \n",
            " 47  YearQuarter_2021Q1                              102229 non-null  int64  \n",
            " 48  YearQuarter_2021Q2                              102229 non-null  int64  \n",
            " 49  YearQuarter_2021Q3                              102229 non-null  int64  \n",
            " 50  YearQuarter_2021Q4                              102229 non-null  int64  \n",
            " 51  YearQuarter_2022Q1                              102229 non-null  int64  \n",
            " 52  YearQuarter_2022Q2                              102229 non-null  int64  \n",
            " 53  YearQuarter_2022Q3                              102229 non-null  int64  \n",
            " 54  YearQuarter_2022Q4                              102229 non-null  int64  \n",
            " 55  YearQuarter_2023Q1                              102229 non-null  int64  \n",
            " 56  new_price                                       102229 non-null  int64  \n",
            " 57  Timestamp                                       102229 non-null  float64\n",
            "dtypes: float64(17), int64(41)\n",
            "memory usage: 45.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TUNING"
      ],
      "metadata": {
        "id": "Zqvb0F4Ttf9b"
      },
      "id": "Zqvb0F4Ttf9b"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# File paths\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "master_results_file_path = os.path.join(subdirectory, 'master_results.csv')\n",
        "\n",
        "# Load or initialize master results table\n",
        "if os.path.exists(master_results_file_path):\n",
        "    master_results = pd.read_csv(master_results_file_path)\n",
        "    print(f\"[INFO] Loaded existing master results table from '{master_results_file_path}'.\")\n",
        "else:\n",
        "    master_results = pd.DataFrame(columns=[\"Target\", \"Model\", \"Type\", \"Train R²\", \"Test R²\", \"MAE\", \"MSE\", \"RMSE\", \"MAPE\", \"Comments\"])\n",
        "    print(f\"[INFO] Initialized a new master results table.\")\n",
        "\n",
        "# Define features and target variables\n",
        "features = filtered_dataset120.drop(columns=['new_price', 'PI'])\n",
        "targets_120 = filtered_dataset120[['new_price', 'PI']]\n",
        "X = features.copy()\n",
        "y = targets_120.copy()\n",
        "\n",
        "# Normalize features and targets\n",
        "feature_scaler = StandardScaler()\n",
        "X_scaled = feature_scaler.fit_transform(X)\n",
        "\n",
        "target_scalers = {col: StandardScaler() for col in targets_120.columns}\n",
        "y_scaled = pd.DataFrame({col: target_scalers[col].fit_transform(targets_120[[col]]).flatten() for col in targets_120.columns})\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Subset the dataset for faster tuning\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
        "X_train_sample_lstm = X_train_sample.reshape((X_train_sample.shape[0], 1, X_train_sample.shape[1]))\n",
        "\n",
        "# Define the model-building function for Keras Tuner\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        return_sequences = i < (num_layers - 1)\n",
        "        model.add(LSTM(\n",
        "            units=hp.Int(f'units_layer_{i+1}', min_value=32, max_value=128, step=32),\n",
        "            activation='relu',\n",
        "            return_sequences=return_sequences,\n",
        "            input_shape=(X_train_sample_lstm.shape[1], X_train_sample_lstm.shape[2]) if i == 0 else None\n",
        "        ))\n",
        "        model.add(Dropout(rate=hp.Choice(f'dropout_layer_{i+1}', values=[0.2, 0.3, 0.4])))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "        learning_rate=hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
        "    ), loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='lstm_hyper_tuning'\n",
        ")\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Loop through targets (new_price and PI) to dynamically update results\n",
        "for target_name in [\"new_price\", \"PI\"]:\n",
        "    if target_name not in y_train.columns:\n",
        "        raise KeyError(f\"Target column '{target_name}' not found in y_train. Available columns are: {y_train.columns.tolist()}\")\n",
        "\n",
        "    # Train and evaluate the model for the current target\n",
        "    y_train_target_sample = y_train_sample[[target_name]].values\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    tuner.search(\n",
        "        X_train_sample_lstm,\n",
        "        y_train_target_sample,\n",
        "        validation_split=0.1,\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Build and train the best model\n",
        "    best_hps = tuner.get_best_hyperparameters(1)[0]\n",
        "    best_model = tuner.hypermodel.build(best_hps)\n",
        "    history = best_model.fit(\n",
        "        X_train_lstm,\n",
        "        y_train[[target_name]].values,\n",
        "        validation_data=(X_test_lstm, y_test[[target_name]].values),\n",
        "        epochs=20,\n",
        "        batch_size=64,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    train_predictions = best_model.predict(X_train_lstm)\n",
        "    test_predictions = best_model.predict(X_test_lstm)\n",
        "\n",
        "    scaler_y = target_scalers[target_name]\n",
        "    train_predictions_rescaled = scaler_y.inverse_transform(train_predictions)\n",
        "    test_predictions_rescaled = scaler_y.inverse_transform(test_predictions)\n",
        "\n",
        "    y_train_rescaled = scaler_y.inverse_transform(y_train[[target_name]])\n",
        "    y_test_rescaled = scaler_y.inverse_transform(y_test[[target_name]])\n",
        "\n",
        "    train_r2 = r2_score(y_train_rescaled, train_predictions_rescaled)\n",
        "    test_r2 = r2_score(y_test_rescaled, test_predictions_rescaled)\n",
        "    mae = mean_absolute_error(y_test_rescaled, test_predictions_rescaled)\n",
        "    mse = mean_squared_error(y_test_rescaled, test_predictions_rescaled)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = np.mean(np.abs((y_test_rescaled - test_predictions_rescaled) / y_test_rescaled)) * 100\n",
        "\n",
        "    # Add results to the master results table\n",
        "    new_results = {\n",
        "        \"Target\": target_name,\n",
        "        \"Type\": \"Neural Network\",\n",
        "        \"Train R²\": train_r2,\n",
        "        \"Test R²\": test_r2,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"MAPE\": mape,\n",
        "        \"Comments\": \"Working Well\" if test_r2 > 0.75 and mape < 10 else \"Needs Improvement\"\n",
        "    }\n",
        "\n",
        "    # Convert new_results to a DataFrame\n",
        "    new_results_df = pd.DataFrame([new_results])\n",
        "\n",
        "    # Check if the target and model already exist in the master results table\n",
        "    existing_row_index = master_results[\n",
        "        (master_results[\"Target\"] == new_results[\"Target\"]) & (master_results[\"Model\"] == new_results[\"Model\"])\n",
        "    ].index\n",
        "\n",
        "    if len(existing_row_index) > 0:\n",
        "        # Update the existing row by replacing its values\n",
        "        master_results.loc[existing_row_index, :] = new_results_df.iloc[0].values\n",
        "    else:\n",
        "        # Append the new results\n",
        "        master_results = pd.concat([master_results, new_results_df], ignore_index=True)\n",
        "\n",
        "# Save updated results\n",
        "master_results.to_csv(master_results_file_path, index=False)\n",
        "print(f\"[INFO] Updated master results saved to '{master_results_file_path}'.\")\n",
        "\n",
        "# Display the final results table\n",
        "print(\"\\nFinal Master Results Table:\")\n",
        "print(master_results.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y8ddTWpHqB-",
        "outputId": "d5f547cf-95df-4878-e237-77394b7188b8"
      },
      "id": "0y8ddTWpHqB-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loaded existing master results table from '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/master_results.csv'.\n",
            "Reloading Tuner from hyperparam_tuning/lstm_hyper_tuning/tuner0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - loss: 0.5877 - val_loss: 0.3600\n",
            "Epoch 2/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.3911 - val_loss: 0.3448\n",
            "Epoch 3/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.3794 - val_loss: 0.3456\n",
            "Epoch 4/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.3686 - val_loss: 0.3359\n",
            "Epoch 5/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.3690 - val_loss: 0.3352\n",
            "Epoch 6/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 0.3644 - val_loss: 0.3315\n",
            "Epoch 7/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - loss: 0.3646 - val_loss: 0.3321\n",
            "Epoch 8/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 0.3567 - val_loss: 0.3321\n",
            "Epoch 9/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.3577 - val_loss: 0.3315\n",
            "\u001b[1m2556/2556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
            "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-dc32087b14d5>:155: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Neural Network' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  master_results.loc[existing_row_index, :] = new_results_df.iloc[0].values\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.1992 - val_loss: 6.6580e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - loss: 0.0211 - val_loss: 3.4260e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: 2.5618e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 3.7161e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0177 - val_loss: 3.9568e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - loss: 0.0174 - val_loss: 4.4070e-04\n",
            "\u001b[1m2556/2556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
            "\u001b[1m639/639\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "[INFO] Updated master results saved to '/content/drive/My Drive/Colab Notebooks/M5 Code and Data/master_results.csv'.\n",
            "\n",
            "Final Master Results Table:\n",
            "   Target                       Model       Train R²  Test R²          MAE          MSE         RMSE         MAPE          Comments              Type\n",
            "new_price           Linear Regression       0.601408 0.595691 4.716642e-01 4.013769e-01 6.335431e-01 4.525806e+02               NaN               NaN\n",
            "new_price     Random Forest Regressor       0.979135 0.850895 2.333770e-01 1.480237e-01 3.847385e-01 1.632906e+02        Best Model               NaN\n",
            "new_price           XGBoost Regressor       0.832455 0.778517 3.312516e-01 2.198767e-01 4.689101e-01 3.637050e+02               NaN               NaN\n",
            "new_price Gradient Boosting Regressor       0.772447 0.752945 3.536000e-01 2.452632e-01 4.952406e-01 3.537886e+02               NaN               NaN\n",
            "       PI           Linear Regression            1.0 1.000000 7.054472e-16 8.754178e-31 9.356376e-16 9.947874e-14        Best Model               NaN\n",
            "       PI     Random Forest Regressor            1.0 1.000000 3.067508e-14 1.684234e-27 4.103942e-14 3.244676e-12               NaN               NaN\n",
            "       PI           XGBoost Regressor       0.999957 0.999957 6.001523e-03 4.316833e-05 6.570261e-03 6.577346e-01               NaN               NaN\n",
            "       PI Gradient Boosting Regressor            1.0 1.000000 1.008244e-08 2.091521e-16 1.446209e-08 8.964217e-07               NaN               NaN\n",
            "new_price                   Base LSTM       0.668216 0.666281 1.425859e+06 3.850930e+12 1.962379e+06 2.122470e+01 Needs Improvement    Neural Network\n",
            "       PI                   Base LSTM       0.999555 0.999558 9.299883e-02 1.698785e-02 1.303375e-01 1.400040e+01 Needs Improvement    Neural Network\n",
            "new_price               Enhanced LSTM       0.686986 0.679755 1.390046e+06 3.695454e+12 1.922356e+06 2.075847e+01 Needs Improvement    Neural Network\n",
            "       PI               Enhanced LSTM       0.999217 0.999198 1.451362e-01 3.081737e-02 1.755488e-01 4.561836e+01 Needs Improvement    Neural Network\n",
            "new_price            Hyper-Tuned LSTM Neural Network 0.668228 6.660502e-01 1.431158e+06 3.853598e+12 1.963058e+06         21.392455 Needs Improvement\n",
            "       PI            Hyper-Tuned LSTM Neural Network 0.999758 9.997433e-01 7.881952e-02 9.866109e-03 9.932829e-02         10.317049 Needs Improvement\n",
            "new_price            Hyper-Tuned LSTM Neural Network 0.668228 6.660502e-01 1.431158e+06 3.853598e+12 1.963058e+06         21.392455 Needs Improvement\n",
            "new_price            Hyper-Tuned LSTM Neural Network 0.668228 6.660502e-01 1.431158e+06 3.853598e+12 1.963058e+06         21.392455 Needs Improvement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BEST HYPER TUNED ARCHITECTURE"
      ],
      "metadata": {
        "id": "97OircKVuCij"
      },
      "id": "97OircKVuCij"
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the best architecture from the hyperparameter tuner\n",
        "print(\"[INFO] Best Hyperparameters for the Tuned LSTM Model:\")\n",
        "print(f\"Number of Layers: {best_hps.get('num_layers')}\")\n",
        "\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    units = best_hps.get(f'units_layer_{i+1}')\n",
        "    dropout = best_hps.get(f'dropout_layer_{i+1}')\n",
        "    print(f\"Layer {i+1}: {units} units, Dropout rate: {dropout}\")\n",
        "\n",
        "learning_rate = best_hps.get('learning_rate')\n",
        "print(f\"Learning Rate: {learning_rate}\")\n",
        "\n",
        "# Alternatively, show a summary of the best model architecture\n",
        "print(\"\\n[INFO] Best Model Architecture:\")\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "wyOD92i2_hrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "c4cb46e0-ce31-4747-d94c-6c86e6c6bac9"
      },
      "id": "wyOD92i2_hrh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Best Hyperparameters for the Tuned LSTM Model:\n",
            "Number of Layers: 3\n",
            "Layer 1: 96 units, Dropout rate: 0.4\n",
            "Layer 2: 32 units, Dropout rate: 0.2\n",
            "Layer 3: 32 units, Dropout rate: 0.2\n",
            "Learning Rate: 0.001\n",
            "\n",
            "[INFO] Best Model Architecture:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m96\u001b[0m)               │          \u001b[38;5;34m58,752\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m96\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">58,752</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,853\u001b[0m (979.90 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,853</span> (979.90 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m83,617\u001b[0m (326.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,617</span> (326.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m167,236\u001b[0m (653.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,236</span> (653.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Dataframe & Data"
      ],
      "metadata": {
        "id": "dvjrSnWQrKfk"
      },
      "id": "dvjrSnWQrKfk"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the subdirectory path\n",
        "subdirectory = '/content/drive/My Drive/Colab Notebooks/M5 Code and Data'\n",
        "\n",
        "# Define file path for 'filtered_dataset120ML.csv' in the subdirectory\n",
        "file_path = os.path.join(subdirectory, 'filtered_dataset120ML.csv')\n",
        "\n",
        "# Check if the file exists, then load it\n",
        "if os.path.exists(file_path):\n",
        "    filtered_dataset120 = pd.read_csv(file_path)\n",
        "    print(f\"File 'filtered_dataset120ML.csv' loaded successfully!\")\n",
        "    print(f\"DataFrame shape: {filtered_dataset120.shape}\")\n",
        "else:\n",
        "    print(f\"File 'filtered_dataset120ML.csv' not found in '{subdirectory}'. Please check the file path.\")"
      ],
      "metadata": {
        "id": "Cd4h9r4G_hwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4417eced-7fd6-484a-f791-69c77785a551"
      },
      "id": "Cd4h9r4G_hwV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File 'filtered_dataset120ML.csv' loaded successfully!\n",
            "DataFrame shape: (102229, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(master_results.head(20))\n",
        "print(master_results.shape)"
      ],
      "metadata": {
        "id": "xvFBqAWu_LOc"
      },
      "id": "xvFBqAWu_LOc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3NjXXmkrSdO"
      },
      "id": "k3NjXXmkrSdO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8tm3qhwrSiP"
      },
      "id": "c8tm3qhwrSiP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e20d30",
      "metadata": {
        "id": "76e20d30"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}